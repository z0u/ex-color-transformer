{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191d5190",
   "metadata": {},
   "source": [
    "# Experiment 2.3: Explicit normalization\n",
    "\n",
    "In [Ex 2.2](./ex-2.2-inhibit-red.ipynb), we applied interventions to the trained, structured color autoencoder — successfully impeding the models capability to operate on the concept of _red_. While it worked to some extent, the latent space looked lumpy, and — since the interventions assume the activations have unit length — we expect the performance will benefit from explicit normalization.\n",
    "\n",
    "Our autoencoders up until now have had a sigmoid function applied to the output of the decoder, to force the values to be in the range $(0,1)$. But this is incorrect, because RGB components should be in the range $[0,1]$ (inclusive).\n",
    "\n",
    "\n",
    "## Hypothesis 1: We're asking too much of the unit norm regularizer\n",
    "\n",
    "If we weakly regularize latent activations to have unit norm, and then explicity normalize them, then the reconstruction capabilities of the model will be better, and the interventions will be more accurate.\n",
    "\n",
    "## Hypothesis 2: Sigmoid harms performance\n",
    "\n",
    "If we remove the sigmoid layer, then the reconstruction capabilities of the model will be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "nbid = '2.3'  # ID for tagging assets\n",
    "nbname = 'Explicit norm'\n",
    "experiment_name = f'Ex {nbid}: {nbname}'\n",
    "project = 'ex-color-transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf0edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup: Logging, Experiment (Modal)\n",
    "import logging\n",
    "\n",
    "import modal\n",
    "\n",
    "from infra.requirements import freeze, project_packages\n",
    "from mini.experiment import Experiment\n",
    "from utils.logging import SimpleLoggingConfig\n",
    "\n",
    "logging_config = (\n",
    "    SimpleLoggingConfig()\n",
    "    .info('notebook', 'utils', 'mini', 'ex_color')\n",
    "    .error('matplotlib.axes')  # Silence warnings about set_aspect\n",
    ")\n",
    "logging_config.apply()\n",
    "\n",
    "# This is the logger for this notebook\n",
    "log = logging.getLogger(f'notebook.{nbid}')\n",
    "\n",
    "run = Experiment(experiment_name, project=project)\n",
    "run.image = modal.Image.debian_slim().pip_install(*freeze(all=True)).add_local_python_source(*project_packages())\n",
    "run.before_each(logging_config.apply)\n",
    "None  # prevent auto-display of this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2028d",
   "metadata": {},
   "source": [
    "## Regularizers\n",
    "\n",
    "Like Ex 2.2:\n",
    "\n",
    "- **Anchor:** pins `red` to $(1,0,0,0)$\n",
    "- **Separate:** angular repulsion to reduce global clumping (applied within each batch)\n",
    "- **Planarity:** pulls vibrant hues to the $[0, 1]$ plane\n",
    "- **Unitarity:** pulls all embeddings to the surface of the unit hypersphere, i.e. it makes the embedding vectors have unit length.\n",
    "\n",
    "But _unlike_ previous experiments:\n",
    "\n",
    "- **Unitarity:** we now only have one unitarity term, which is applied very weakly to the outputs of the encoder. Previously there were two terms and they were stronger (because the model didn't explicitly normalize the activations).\n",
    "\n",
    "Why have a unitarity regularizer at all, if the activations are explicitly normalized? Because this gives the upstream layers a hint about what the downstream layers expect — otherwise that signal would be destroyed by the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e10c434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mini.temporal.dopesheet import Dopesheet\n",
    "from ex_color.loss import Anchor, Separate, Planarity, Unitarity, RegularizerConfig\n",
    "\n",
    "from ex_color.training import TrainingModule\n",
    "\n",
    "RED = (1, 0, 0, 0)\n",
    "\n",
    "ALL_REGULARIZERS = [\n",
    "    RegularizerConfig(\n",
    "        name='reg-unit',\n",
    "        compute_loss_term=Unitarity(),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-anchor',\n",
    "        compute_loss_term=Anchor(torch.tensor(RED, dtype=torch.float32)),\n",
    "        label_affinities={'red': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-separate',\n",
    "        compute_loss_term=Separate(power=100.0, shift=True),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-planar',\n",
    "        compute_loss_term=Planarity(),\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "import logging\n",
    "from typing import override\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CNColorMLP(nn.Module):\n",
    "    \"\"\"A clamped-and-normalized RGB-to-RGB bottlenecked autoencoder\"\"\"\n",
    "\n",
    "    def __init__(self, k_bottleneck: int, sigmoid_out: bool):\n",
    "        super().__init__()\n",
    "        # RGB input (3D) → hidden layer → bottleneck → hidden layer → RGB output\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, k_bottleneck),\n",
    "        )\n",
    "\n",
    "        self.bottleneck = L2Norm()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(k_bottleneck, 16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.Sigmoid() if sigmoid_out else nn.Identity(),\n",
    "        )\n",
    "\n",
    "    @override  # Overridden to narrow types\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return super().__call__(x)\n",
    "\n",
    "    @override\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # Get the bottleneck representation (captured by a hook for regularization)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Normalize\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Decode back to RGB\n",
    "        x = self.decoder(x)\n",
    "        return x if self.training else torch.clamp(x, 0, 1)\n",
    "\n",
    "\n",
    "class L2Norm(nn.Module):\n",
    "    def forward(self, x: Tensor):\n",
    "        return nn.functional.normalize(x, dim=-1)\n",
    "\n",
    "\n",
    "def make_model(sigmoid_out: bool):\n",
    "    return CNColorMLP(4, sigmoid_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376072",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is the same as last time:\n",
    "- Train: an HSV cube (of RGB values), weighted to avoid over-sampling desaturated and dark colors\n",
    "- Test: an RGB cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de07fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cube_sampler import vibrancy\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "from ex_color.labelling import collate_with_generated_labels\n",
    "\n",
    "\n",
    "def prep_data() -> tuple[DataLoader, Tensor]:\n",
    "    \"\"\"\n",
    "    Prepare data for training.\n",
    "\n",
    "    Returns: (train, val)\n",
    "    \"\"\"\n",
    "    hsv_cube = ColorCube.from_hsv(\n",
    "        h=arange_cyclic(step_size=10 / 360),\n",
    "        s=np.linspace(0, 1, 10),\n",
    "        v=np.linspace(0, 1, 10),\n",
    "    )\n",
    "    hsv_tensor = torch.tensor(hsv_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    vibrancy_tensor = torch.tensor(vibrancy(hsv_cube).flatten(), dtype=torch.float32)\n",
    "    hsv_dataset = TensorDataset(hsv_tensor, vibrancy_tensor)\n",
    "\n",
    "    labeller = partial(\n",
    "        collate_with_generated_labels,\n",
    "        soft=False,  # Use binary labels (stochastic) to simulate the labelling of internet text\n",
    "        red=0.5,\n",
    "        vibrant=0.5,\n",
    "    )\n",
    "    # Desaturated and dark colors are over-represented in the cube, so we use a weighted sampler to balance them out\n",
    "    hsv_loader = DataLoader(\n",
    "        hsv_dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=2,\n",
    "        sampler=WeightedRandomSampler(\n",
    "            weights=hsv_cube.bias.flatten().tolist(),\n",
    "            num_samples=len(hsv_dataset),\n",
    "            replacement=True,\n",
    "        ),\n",
    "        collate_fn=labeller,\n",
    "    )\n",
    "\n",
    "    rgb_cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 8),\n",
    "        g=np.linspace(0, 1, 8),\n",
    "        b=np.linspace(0, 1, 8),\n",
    "    )\n",
    "    rgb_tensor = torch.tensor(rgb_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    return hsv_loader, rgb_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb906",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This time we'll train two variants of the model: both with the same regularizers and normalization, but one with sigmoid applied to the output (like last time), and one without.\n",
    "\n",
    "Like in Ex 2.2, the model is trained with PyTorch Lightning, with regularizers applied as custom hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c22398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ex_color.inference import InferenceModule\n",
    "from ex_color.intervention.intervention import InterventionConfig\n",
    "\n",
    "\n",
    "# @run.thither(env={'WANDB_API_KEY': wandb.Api().api_key})\n",
    "async def train(\n",
    "    dopesheet: Dopesheet,\n",
    "    regularizers: list[RegularizerConfig],\n",
    "    sigmoid_out: bool,\n",
    ") -> CNColorMLP:\n",
    "    \"\"\"Train the model with the given dopesheet and variant.\"\"\"\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    from ex_color.seed import set_deterministic_mode\n",
    "\n",
    "    from utils.progress.lightning import LightningProgress\n",
    "\n",
    "    log.info(f'Training with: {[r.name for r in regularizers]}')\n",
    "\n",
    "    seed = 0\n",
    "    set_deterministic_mode(seed)\n",
    "\n",
    "    hsv_loader, _ = prep_data()\n",
    "\n",
    "    model = make_model(sigmoid_out)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log.debug(f'Model initialized with {total_params:,} trainable parameters.')\n",
    "\n",
    "    training_module = TrainingModule(model, dopesheet, torch.nn.MSELoss(), regularizers)\n",
    "\n",
    "    logger = WandbLogger(experiment_name + (', sigmoid' if sigmoid_out else ', linear'), project='ex-color-transformer')\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_steps=len(dopesheet),\n",
    "        callbacks=[\n",
    "            LightningProgress(),\n",
    "        ],\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        # enable_progress_bar=True,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    print(f'max_steps: {len(dopesheet)}, hsv_loader length: {len(hsv_loader)}')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        trainer.fit(training_module, hsv_loader)\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "    # This is only a small model, so it's OK to return it rather than storing and loading a checkpoint remotely\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003a4973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 6.3 li.fa.ut.se:Seed set to 0\n",
      "I 6.3 ex.se:   PyTorch set to deterministic mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 6.4 li.py.ut.ra:GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 6.4 li.py.ut.ra:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 6.4 li.py.ut.ra:HPU available: False, using: 0 HPUs\n",
      "max_steps: 3001, hsv_loader length: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mz0r\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250905_065249-qjodfyjo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/z0r/ex-color-transformer/runs/qjodfyjo' target=\"_blank\">Ex 2.3: Explicit norm, sigmoid</a></strong> to <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/z0r/ex-color-transformer/runs/qjodfyjo' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/qjodfyjo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width: 100%; padding: 5px 0; font-family: monospace\">\n",
       "  <div style=\"position: relative; height: calc(1em * 5/3); width: 100%; margin-bottom: 2em\">\n",
       "    <div style=\"position: absolute; top: 100%; height: 3.5px; left: 0; width: 100%; background: linear-gradient(to right, var(--h1) 0.0%, var(--h0) 2.0%, var(--h0) 4.1%, var(--h0) 6.1%, var(--h0) 8.2%, var(--h0) 10.2%, var(--h0) 12.2%, var(--h0) 14.3%, var(--h0) 16.3%, var(--h0) 18.4%, var(--h0) 20.4%, var(--h0) 22.4%, var(--h0) 24.5%, var(--h0) 26.5%, var(--h0) 28.6%, var(--h0) 30.6%, var(--h0) 32.7%, var(--h0) 34.7%, var(--h1) 36.7%, var(--h0) 38.8%, var(--h0) 40.8%, var(--h0) 42.9%, var(--h0) 44.9%, var(--h0) 46.9%, var(--h0) 49.0%, var(--h0) 51.0%, var(--h0) 53.1%, var(--h0) 55.1%, var(--h0) 57.1%, var(--h0) 59.2%, var(--h0) 61.2%, var(--h0) 63.3%, var(--h0) 65.3%, var(--h0) 67.3%, var(--h0) 69.4%, var(--h0) 71.4%, var(--h0) 73.5%, var(--h1) 75.5%, var(--h0) 77.6%, var(--h0) 79.6%, var(--h0) 81.6%, var(--h0) 83.7%, var(--h0) 85.7%, var(--h0) 87.8%, var(--h0) 89.8%, var(--h0) 91.8%, var(--h0) 93.9%, var(--h0) 95.9%, var(--h0) 98.0%, var(--h1) 100.0%);--h0:color(from currentColor srgb r g b / 0.11);--h1:color(from currentColor srgb r g b / 0.44)\"></div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 1.9%; border-left: 0.5px solid currentColor\">0.0161</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 13.3%; border-left: 0.5px solid currentColor\">0.0101</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 24.7%; border-left: 0.5px solid currentColor\">0.0088</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 36.1%; border-left: 0.5px solid currentColor\">0.0200</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 47.5%; border-left: 0.5px solid currentColor\">0.0130</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 58.8%; border-left: 0.5px solid currentColor\">0.0019</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 70.2%; border-left: 0.5px solid currentColor\">0.0013</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 81.6%; border-left: 0.5px solid currentColor\">0.0003</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; right: 0.0%; border-right: 0.5px solid currentColor\">0.0002</div>\n",
       "    <div style=\"position: absolute; bottom: -4px; left: calc(100.0% - 4px)\">\n",
       "      <div style=\"border-left: 4px solid transparent; border-right: 4px solid transparent; border-bottom: 4px solid currentColor\"></div>\n",
       "    </div>\n",
       "    <div style=\"position: absolute; height: 100%; width: 100.0%; background-color: color(from currentColor srgb r g b / 0.1); border-bottom: 1px solid currentColor\"></div>\n",
       "    <div style=\"position: absolute; width: 100%; height: 100%; text-align: center; line-height: calc((1em * 5/3) / 0.9); font-size: 90%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; border-bottom: 1px dashed color(from currentColor srgb r g b / 0.5)\"><b>Training</b>: 100.0% [3001/3001] [<b>00:18</b>/<00:00, 165.05 it/s]</div>\n",
       "  </div>\n",
       "  <div style=\"display: grid; grid-template-columns: repeat(2, minmax(80px, 1fr)); gap: 5px 0px; width: 100%; margin: 1em 0; font-size: 0.85em\">\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">v_num</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">train_loss</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">fyjo</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">0.0002025</div>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "Training: 100.0% [3001/3001]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phase: Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=3001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 26.9 li.py.ut.ra:`Trainer.fit` stopped: `max_steps=3001` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>▇▄▄▇▅▄▄▄▇▃▄▇█▃▅▄▃▄▂▃▂▄▂▃▄▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_recon</td><td>█▃▃▂▂▂▄▂▂▂▅▄▄▅▂▃▃▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-anchor</td><td>▁▁▁▁▁█▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▁▁▂▁▁</td></tr><tr><td>train_reg-planar</td><td>▂▄▁▆▆▃▁▁█▁▁▆▁▆▂▂▁▁▂▁▁▂▁▄▃▁▁▁▁▁▁▂▂▁▁▁▁▂▂▂</td></tr><tr><td>train_reg-separate</td><td>▃▃▃▃▂▄▃▂▁▂▂█▃▂▂▂▁▂▂▂▁▂▃▂▁▂▂▂▁▂▂▂▁▂▁▂▂▃▂▃</td></tr><tr><td>train_reg-unit</td><td>█▇▆▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>52</td></tr><tr><td>train_loss</td><td>0.00019</td></tr><tr><td>train_recon</td><td>0.00019</td></tr><tr><td>train_reg-anchor</td><td>0</td></tr><tr><td>train_reg-planar</td><td>0.03255</td></tr><tr><td>train_reg-separate</td><td>0.45008</td></tr><tr><td>train_reg-unit</td><td>0.00431</td></tr><tr><td>trainer/global_step</td><td>2999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ex 2.3: Explicit norm, sigmoid</strong> at: <a href='https://wandb.ai/z0r/ex-color-transformer/runs/qjodfyjo' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/qjodfyjo</a><br> View project at: <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250905_065249-qjodfyjo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with run():\n",
    "    model_sigmoid = await train(Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv'), ALL_REGULARIZERS, sigmoid_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc7e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 29.2 li.fa.ut.se:Seed set to 0\n",
      "I 29.2 ex.se:  PyTorch set to deterministic mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 29.3 li.py.ut.ra:GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 29.3 li.py.ut.ra:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 29.3 li.py.ut.ra:HPU available: False, using: 0 HPUs\n",
      "max_steps: 3001, hsv_loader length: 57\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250905_065311-8r5o2ag3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/z0r/ex-color-transformer/runs/8r5o2ag3' target=\"_blank\">Ex 2.3: Explicit norm, linear</a></strong> to <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/z0r/ex-color-transformer/runs/8r5o2ag3' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/8r5o2ag3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width: 100%; padding: 5px 0; font-family: monospace\">\n",
       "  <div style=\"position: relative; height: calc(1em * 5/3); width: 100%; margin-bottom: 2em\">\n",
       "    <div style=\"position: absolute; top: 100%; height: 3.5px; left: 0; width: 100%; background: linear-gradient(to right, var(--h1) 0.0%, var(--h0) 2.0%, var(--h0) 4.1%, var(--h0) 6.1%, var(--h0) 8.2%, var(--h0) 10.2%, var(--h0) 12.2%, var(--h0) 14.3%, var(--h0) 16.3%, var(--h0) 18.4%, var(--h0) 20.4%, var(--h0) 22.4%, var(--h0) 24.5%, var(--h0) 26.5%, var(--h0) 28.6%, var(--h0) 30.6%, var(--h0) 32.7%, var(--h0) 34.7%, var(--h1) 36.7%, var(--h0) 38.8%, var(--h0) 40.8%, var(--h0) 42.9%, var(--h0) 44.9%, var(--h0) 46.9%, var(--h0) 49.0%, var(--h0) 51.0%, var(--h0) 53.1%, var(--h0) 55.1%, var(--h0) 57.1%, var(--h0) 59.2%, var(--h0) 61.2%, var(--h0) 63.3%, var(--h0) 65.3%, var(--h0) 67.3%, var(--h0) 69.4%, var(--h0) 71.4%, var(--h0) 73.5%, var(--h1) 75.5%, var(--h0) 77.6%, var(--h0) 79.6%, var(--h0) 81.6%, var(--h0) 83.7%, var(--h0) 85.7%, var(--h0) 87.8%, var(--h0) 89.8%, var(--h0) 91.8%, var(--h0) 93.9%, var(--h0) 95.9%, var(--h0) 98.0%, var(--h1) 100.0%);--h0:color(from currentColor srgb r g b / 0.11);--h1:color(from currentColor srgb r g b / 0.44)\"></div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 1.9%; border-left: 0.5px solid currentColor\">0.0251</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 13.3%; border-left: 0.5px solid currentColor\">0.0070</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 24.7%; border-left: 0.5px solid currentColor\">0.0121</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 36.1%; border-left: 0.5px solid currentColor\">0.0058</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 47.5%; border-left: 0.5px solid currentColor\">0.0104</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 58.8%; border-left: 0.5px solid currentColor\">0.0017</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 70.2%; border-left: 0.5px solid currentColor\">0.0014</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 81.6%; border-left: 0.5px solid currentColor\">0.0001</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; right: 0.0%; border-right: 0.5px solid currentColor\">0.0000</div>\n",
       "    <div style=\"position: absolute; bottom: -4px; left: calc(100.0% - 4px)\">\n",
       "      <div style=\"border-left: 4px solid transparent; border-right: 4px solid transparent; border-bottom: 4px solid currentColor\"></div>\n",
       "    </div>\n",
       "    <div style=\"position: absolute; height: 100%; width: 100.0%; background-color: color(from currentColor srgb r g b / 0.1); border-bottom: 1px solid currentColor\"></div>\n",
       "    <div style=\"position: absolute; width: 100%; height: 100%; text-align: center; line-height: calc((1em * 5/3) / 0.9); font-size: 90%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; border-bottom: 1px dashed color(from currentColor srgb r g b / 0.5)\"><b>Training</b>: 100.0% [3001/3001] [<b>00:17</b>/<00:00, 171.13 it/s]</div>\n",
       "  </div>\n",
       "  <div style=\"display: grid; grid-template-columns: repeat(2, minmax(80px, 1fr)); gap: 5px 0px; width: 100%; margin: 1em 0; font-size: 0.85em\">\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">v_num</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">train_loss</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">2ag3</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">2.266e-05</div>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "Training: 100.0% [3001/3001]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phase: Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=3001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 48.0 li.py.ut.ra:`Trainer.fit` stopped: `max_steps=3001` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▄▆▅▄▄▃▄▃▇▅▃▃▅▃▂▃▄▄▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_recon</td><td>█▂▂▂▁▂▂▁▁▂▂▂▂▂▂▂▁▂▃▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-anchor</td><td>▁▁▁▁█▁▃▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▃▁▁▃▁▁</td></tr><tr><td>train_reg-planar</td><td>▄▃▁█▁▁▃▁▁▂▁▁▄▂▃▄▁▂▁▃▁▁▄▁▃▄▁▂▁▁▁▁▁▃▂▁▃▁▃▃</td></tr><tr><td>train_reg-separate</td><td>▃▂▃▂▂▃▅▂▂▂▂▂▂▂█▂▂▂▂▁▁▂▃▁▂▂▂▁▁▂▁▁▁▂▁▁▁▂▂▂</td></tr><tr><td>train_reg-unit</td><td>██▇▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>52</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>train_recon</td><td>2e-05</td></tr><tr><td>train_reg-anchor</td><td>0</td></tr><tr><td>train_reg-planar</td><td>0.05697</td></tr><tr><td>train_reg-separate</td><td>0.41534</td></tr><tr><td>train_reg-unit</td><td>0.00611</td></tr><tr><td>trainer/global_step</td><td>2999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ex 2.3: Explicit norm, linear</strong> at: <a href='https://wandb.ai/z0r/ex-color-transformer/runs/8r5o2ag3' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/8r5o2ag3</a><br> View project at: <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250905_065311-8r5o2ag3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with run():\n",
    "    model = await train(Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv'), ALL_REGULARIZERS, sigmoid_out=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9688ac3",
   "metadata": {},
   "source": [
    "## Inference ('test-time')\n",
    "\n",
    "We wrap the model that we trained above in an `InferenceModule`, which knows how to apply our interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d2de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @run.thither\n",
    "async def infer(\n",
    "    model: CNColorMLP,\n",
    "    interventions: list[InterventionConfig],\n",
    "    test_data: Tensor,\n",
    ") -> Tensor:\n",
    "    \"\"\"Run inference with the given model and interventions.\"\"\"\n",
    "    import lightning as L\n",
    "\n",
    "    inference_module = InferenceModule(model, interventions)\n",
    "    trainer = L.Trainer(\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    reconstructed_colors_batches = trainer.predict(\n",
    "        inference_module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert reconstructed_colors_batches is not None\n",
    "    # Flatten the list of batches to a single list of tensors\n",
    "    reconstructed_colors = [item for batch in reconstructed_colors_batches for item in batch]\n",
    "    # Reshape to match input\n",
    "    return torch.cat(reconstructed_colors).reshape(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6940577",
   "metadata": {},
   "source": [
    "## Sigmoid output with no intervention\n",
    "\n",
    "Let's see how well the model reconstructs colors _without_ any interventions. First, we'll see how it looks with the sigmoid function applied to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4381b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-true-colors.dark.png?v=sZaNEetpSyIdknajOxYPPNuhlg6vQ9zgwz6kXoyWqNw\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-true-colors.png?v=sZaNEetpSyIdknajOxYPPNuhlg6vQ9zgwz6kXoyWqNw\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-true-colors.png?v=sZaNEetpSyIdknajOxYPPNuhlg6vQ9zgwz6kXoyWqNw\" alt=\"Plot showing four slices of the HSV cube, titled &quot;True colors · V vs H by S&quot;. Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"True colors · V vs H by S\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from utils.nb import displayer_mpl\n",
    "from ex_color.vis import plot_colors\n",
    "\n",
    "\n",
    "hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 24),\n",
    "    s=np.linspace(0, 1, 4),\n",
    "    v=np.linspace(0, 1, 8),\n",
    ").permute('svh')\n",
    "x_hsv = torch.tensor(hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "hd_hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 240),\n",
    "    s=np.linspace(0, 1, 48),\n",
    "    v=np.linspace(0, 1, 48),\n",
    ")\n",
    "hd_x_hsv = torch.tensor(hd_hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "rgb_cube = ColorCube.from_rgb(\n",
    "    r=np.linspace(0, 1, 20),\n",
    "    g=np.linspace(0, 1, 20),\n",
    "    b=np.linspace(0, 1, 20),\n",
    ")\n",
    "x_rgb = torch.tensor(rgb_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-true-colors.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\"\"\",\n",
    ") as show:\n",
    "    show(lambda: plot_colors(hsv_cube, title='True colors', colors=x_hsv.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14da6f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-no-interventio-sigmoid.dark.png?v=f3x4j3MEbshWtndSSS_5EEXd5-uz2RS0bldCOl3Q6O0\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-no-interventio-sigmoid.png?v=f3x4j3MEbshWtndSSS_5EEXd5-uz2RS0bldCOl3Q6O0\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-pred-colors-no-interventio-sigmoid.png?v=f3x4j3MEbshWtndSSS_5EEXd5-uz2RS0bldCOl3Q6O0\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · no intervention, sigmoid output · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree somewhat, but some differences are visible; for example, &quot;white&quot; is slightly gray, and many of the fully-saturated colors are less saturated than they should be.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · no intervention, sigmoid output · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree somewhat, but some differences are visible; for example, \"white\" is slightly gray, and many of the fully-saturated colors are less saturated than they should be."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-no-intervention-sigmoid.dark.png?v=YmfRW3Z6dH3YFxSNTUq5hewo1ZwxQxG2_Bf82FqtlMY\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-no-intervention-sigmoid.png?v=YmfRW3Z6dH3YFxSNTUq5hewo1ZwxQxG2_Bf82FqtlMY\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-loss-colors-no-intervention-sigmoid.png?v=YmfRW3Z6dH3YFxSNTUq5hewo1ZwxQxG2_Bf82FqtlMY\" alt=\"Line chart showing loss per color, titled &quot;Reconstruction error · no intervention, sigmoid output&quot;. Y-axis: mean square error, ranging from zero to 0.0016. X-axis: hue. There is a lot of variation; the lines of color are quite messy.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, titled \"Reconstruction error · no intervention, sigmoid output\". Y-axis: mean square error, ranging from zero to 0.0016. X-axis: hue. There is a lot of variation; the lines of color are quite messy."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.0016\n",
      "Median MSE: 6.3e-05\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "interventions = []\n",
    "y_hsv = await infer(model_sigmoid, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model_sigmoid, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-no-interventio-sigmoid.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree somewhat, but some differences are visible; for example, \"white\" is slightly gray, and many of the fully-saturated colors are less saturated than they should be.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors · no intervention, sigmoid output',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "median_loss = per_color_loss.median().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-no-intervention-sigmoid.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. There is a lot of variation; the lines of color are quite messy.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            title='Reconstruction error · no intervention, sigmoid output',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')\n",
    "print(f'Median MSE: {median_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac7f1c",
   "metadata": {},
   "source": [
    "OK, that looks similar to the output of Ex 2.2. The reconstruction loss curves look a lot messier, but the range is much smaller — by roughly an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ec7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ex_color.inference import InferenceModule\n",
    "\n",
    "\n",
    "async def infer_with_latent_capture(\n",
    "    model: CNColorMLP, interventions: list[InterventionConfig], test_data: Tensor, layer_name: str = 'bottleneck'\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    module = InferenceModule(model, interventions, capture_layers=[layer_name])\n",
    "    import lightning as L\n",
    "\n",
    "    trainer = L.Trainer(enable_checkpointing=False, enable_model_summary=False, enable_progress_bar=False)\n",
    "    batches = trainer.predict(\n",
    "        module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert batches is not None\n",
    "    preds = [item for batch in batches for item in batch]\n",
    "    y = torch.cat(preds).reshape(test_data.shape)\n",
    "    # Read captured activations as a flat [N, D] tensor\n",
    "    latents = module.read_captured(layer_name)\n",
    "    return y, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b4aa8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-no-intervention-sigmoid.dark.png?v=od79Da--SMNO45sbxxk_d3SfK4adM3OGQkxG9t4p5ns\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-no-intervention-sigmoid.png?v=od79Da--SMNO45sbxxk_d3SfK4adM3OGQkxG9t4p5ns\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-latents-no-intervention-sigmoid.png?v=od79Da--SMNO45sbxxk_d3SfK4adM3OGQkxG9t4p5ns\" alt=\"Three spherical plots, titled &quot;Latents · no intervention, sigmoid&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It&#x27;s fairly regular but has a couple of bulges. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well, but slight differences can be seen if you look closely.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents · no intervention, sigmoid\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It's fairly regular but has a couple of bulges. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well, but slight differences can be seen if you look closely."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d\n",
    "\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model_sigmoid, [], x_rgb, 'bottleneck')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-no-intervention-sigmoid.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It's fairly regular but has a couple of bulges. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well, but slight differences can be seen if you look closely.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · no intervention, sigmoid',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa577c56",
   "metadata": {},
   "source": [
    "The latent space looks considerably better than Ex 2.2, and only required _one tenth_ the number of training steps. So we're getting an order of magnitude better performance, with an order of magnitude less compute. Not bad.\n",
    "\n",
    "Can we push it further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c9377",
   "metadata": {},
   "source": [
    "## Linear output with no intervention\n",
    "\n",
    "Let's run that again, this time without the sigmoid function applied to the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70076bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-no-intervention.dark.png?v=WwLGgFXDTMwme_hPRB8Q7gIPeoehrBBYqHAFrrfzdCo\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-no-intervention.png?v=WwLGgFXDTMwme_hPRB8Q7gIPeoehrBBYqHAFrrfzdCo\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-pred-colors-no-intervention.png?v=WwLGgFXDTMwme_hPRB8Q7gIPeoehrBBYqHAFrrfzdCo\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · no intervention, linear output · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree very well; it&#x27;s hard to see any differences.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · no intervention, linear output · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree very well; it's hard to see any differences."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-no-intervention.dark.png?v=wix9zPT7HTfCvfgKJtB9hflQirzLry20Dzp5-JRLDNc\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-no-intervention.png?v=wix9zPT7HTfCvfgKJtB9hflQirzLry20Dzp5-JRLDNc\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-loss-colors-no-intervention.png?v=wix9zPT7HTfCvfgKJtB9hflQirzLry20Dzp5-JRLDNc\" alt=\"Line chart showing loss per color, titled &quot;Reconstruction error · no intervention, linear output&quot;. Y-axis: mean square error, ranging from zero to 0.0017. X-axis: hue. The range of loss values is small and the series are quite neat, but there are two notable peaks at blue and green, and smaller peaks at red and yellow.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, titled \"Reconstruction error · no intervention, linear output\". Y-axis: mean square error, ranging from zero to 0.0017. X-axis: hue. The range of loss values is small and the series are quite neat, but there are two notable peaks at blue and green, and smaller peaks at red and yellow."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.0017\n",
      "Median MSE: 1.6e-05\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "interventions = []\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-no-intervention.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree very well; it's hard to see any differences.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors · no intervention, linear output',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "median_loss = per_color_loss.median().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-no-intervention.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. The range of loss values is small and the series are quite neat, but there are two notable peaks at blue and green, and smaller peaks at red and yellow.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            title='Reconstruction error · no intervention, linear output',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')\n",
    "print(f'Median MSE: {median_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c6e78",
   "metadata": {},
   "source": [
    "That's very good: Visually, the reconstructed colors agree extremely well with the true colors. White no longer looks \"off-white\", and it's hard to see the differences in the fully-saturated colors. The maximum reconstruction loss is about the same as the model that did use sigmoid, but the median loss is smaller by a factor of six — and the curves are less \"messy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a757ab80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-no-intervention.dark.png?v=qPqoqKjEwnVrF8q2j7Vgn0M0AUb6b0ghPP3Um03wlCs\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-no-intervention.png?v=qPqoqKjEwnVrF8q2j7Vgn0M0AUb6b0ghPP3Um03wlCs\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-latents-no-intervention.png?v=qPqoqKjEwnVrF8q2j7Vgn0M0AUb6b0ghPP3Um03wlCs\" alt=\"Three spherical plots, titled &quot;Latents · no intervention&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It is very regular in shape. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents · no intervention\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It is very regular in shape. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d\n",
    "\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, [], x_rgb, 'bottleneck')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-no-intervention.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. It is very regular in shape. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree very well.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · no intervention',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68adcf20",
   "metadata": {},
   "source": [
    "Latent space looks extremely good: very regular and round.\n",
    "\n",
    "From here on, we'll use the linear model (i.e. without sigmoid applied to the outputs). Let's re-run the suppression and repulsion tests from Ex 2.2 with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4f1dc",
   "metadata": {},
   "source": [
    "## Suppression\n",
    "\n",
    "Now that we have our model, let's try suppressing _red_. We'll use the `Suppression` function developed in [Ex 2.1](./ex-2.1-intervention-lobe.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8cecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-suppression.dark.png?v=3Wkb7FO3tntwHMxlwVl3max4-tK2zYCtvKN15Gck9Ko\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-suppression.png?v=3Wkb7FO3tntwHMxlwVl3max4-tK2zYCtvKN15Gck9Ko\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-pred-colors-suppression.png?v=3Wkb7FO3tntwHMxlwVl3max4-tK2zYCtvKN15Gck9Ko\" alt=\"Plot showing four slices of the HSV cube, titled &quot;{Predicted colors with suppression · V vs H by S}&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but &quot;red&quot; and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. &quot;Red-orange&quot; actually appears to be green, moreso even than yellow (which is geometrically closer to green).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"{Predicted colors with suppression · V vs H by S}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. \"Red-orange\" actually appears to be green, moreso even than yellow (which is geometrically closer to green)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-suppression.dark.png?v=CSvbogxa21xIs04hyjyAbv0saAdv9pzl_AYsb5Ja6Gg\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-suppression.png?v=CSvbogxa21xIs04hyjyAbv0saAdv9pzl_AYsb5Ja6Gg\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-loss-colors-suppression.png?v=CSvbogxa21xIs04hyjyAbv0saAdv9pzl_AYsb5Ja6Gg\" alt=\"Line chart showing loss per color, titled &quot;Reconstruction error · suppression&quot;. Y-axis: mean square error, ranging from zero to 0.19. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, titled \"Reconstruction error · suppression\". Y-axis: mean square error, ranging from zero to 0.19. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.19\n",
      "Median MSE: 1.9e-05\n"
     ]
    }
   ],
   "source": [
    "from math import cos, pi\n",
    "\n",
    "import torch\n",
    "\n",
    "from ex_color.intervention import BoundedFalloff, InterventionConfig, Suppression\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "suppression = Suppression(\n",
    "    torch.tensor(RED, dtype=torch.float32),  # Constant!\n",
    "    BoundedFalloff(\n",
    "        0,  # within 60°\n",
    "        1,  # completely squash fully-aligned vectors\n",
    "        2,  # soft rim, sharp hub\n",
    "    ),\n",
    ")\n",
    "\n",
    "interventions = [InterventionConfig(suppression, ['bottleneck'])]\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-suppression.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{{title}}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. \"Red-orange\" actually appears to be green, moreso even than yellow (which is geometrically closer to green).\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors with suppression',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "median_loss = per_color_loss.median().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-suppression.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            title='Reconstruction error · suppression',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')\n",
    "print(f'Median MSE: {median_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35e4b3",
   "metadata": {},
   "source": [
    "This looks good — much like the suppression results from Ex 2.2, but _much_ smoother — which should mean that the intervention would have more predictable effects and be more targeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec409f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-suppression.dark.png?v=kXN6DLgOH7QAGzPy24UeR0uCw5OKnOz_dsOyd0LYjcU\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-suppression.png?v=kXN6DLgOH7QAGzPy24UeR0uCw5OKnOz_dsOyd0LYjcU\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-latents-suppression.png?v=kXN6DLgOH7QAGzPy24UeR0uCw5OKnOz_dsOyd0LYjcU\" alt=\"Three spherical plots, titled &quot;Latents · suppression&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where &quot;red&quot; should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm colors in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. &quot;Red&quot; itself is in fact not visible, being buried somewhere inside the sphere.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents · suppression\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm colors in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. \"Red\" itself is in fact not visible, being buried somewhere inside the sphere."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d, ConicalAnnotation\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, interventions, x_rgb, 'bottleneck')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-suppression.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm colors in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. \"Red\" itself is in fact not visible, being buried somewhere inside the sphere.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · suppression',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "            annotations=[\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - suppression.falloff.a),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                    dashes=theme.val((8, 8), dark=(4, 4)),\n",
    "                    gapcolor=theme.val('#fff4', dark='#0004'),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4215",
   "metadata": {},
   "source": [
    "This is _really_ good. Just like in Ex 2.2, the top of the first plot has been pushed in — but it's very regular. The others show the deformation too, with warmer colors in the center. We can see colors close to red in the center of the middle plot, showing significant disagreement with the true colors, as expected.\n",
    "\n",
    "The interior of the sphere is still out of distribution for the decoder; nevertheless the intervention is causing the kind of reconstruction loss we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8eb019",
   "metadata": {},
   "source": [
    "## Repulsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-repulsion.dark.png?v=C2XhimZWXHpjoMC6kOCwEIRywsuQ13dPEBYm_MEluAg\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-pred-colors-repulsion.png?v=C2XhimZWXHpjoMC6kOCwEIRywsuQ13dPEBYm_MEluAg\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-pred-colors-repulsion.png?v=C2XhimZWXHpjoMC6kOCwEIRywsuQ13dPEBYm_MEluAg\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors with repulsion · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but &quot;red&quot; and nearby colors are clearly different, and different again from how the suppression intervention looked: &quot;red&quot; itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. &quot;Red-orange&quot; actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors with repulsion · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different, and different again from how the suppression intervention looked: \"red\" itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. \"Red-orange\" actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-repulsion.dark.png?v=d2UoIIEJpuQG3U6K3U3q5VMR2-mD2y-hcQalcEutE6A\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-loss-colors-repulsion.png?v=d2UoIIEJpuQG3U6K3U3q5VMR2-mD2y-hcQalcEutE6A\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-loss-colors-repulsion.png?v=d2UoIIEJpuQG3U6K3U3q5VMR2-mD2y-hcQalcEutE6A\" alt=\"Line chart showing loss per color, titled &quot;Reconstruction error · repulsion&quot;. Y-axis: mean square error, ranging from zero to 0.12. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, titled \"Reconstruction error · repulsion\". Y-axis: mean square error, ranging from zero to 0.12. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.12\n",
      "Median MSE: 1.9e-05\n"
     ]
    }
   ],
   "source": [
    "from math import cos, pi\n",
    "\n",
    "import torch\n",
    "\n",
    "from ex_color.intervention import FastBezierMapper, InterventionConfig, Repulsion\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "repulsion = Repulsion(\n",
    "    torch.tensor([1, 0, 0, 0], dtype=torch.float32),  # Constant!\n",
    "    FastBezierMapper(\n",
    "        0,  # Constrain effect to within 60° cone\n",
    "        cos(pi / 3),  # Create 30° hole (negative cone) around concept vector\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "interventions = [InterventionConfig(repulsion, ['bottleneck'])]\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-repulsion.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different, and different again from how the suppression intervention looked: \"red\" itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. \"Red-orange\" actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors with repulsion',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-repulsion.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            title='Reconstruction error · repulsion',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')\n",
    "print(f'Median MSE: {median_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d947b",
   "metadata": {},
   "source": [
    "This looks similar to the _suppression_ result, but the maximum reconstruction loss is lower. That's to be expected, since the repulsion regularizer is configured to push fully-aligned colors 60° away, whereas suppression is configured to squash aligned activations to zero.\n",
    "\n",
    "The quality of the reconstructed colors is subjectively better to my eyes: red is still red, but darker; whereas with suppression, red shifted to be green. It's hard to say whether that's due to the type of transform or the strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083b6bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-repulsion.dark.png?v=tpAoc2U6_2Ml49zBHqmkkSbb7jugL95LSz6XYYjGIhc\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.3-latents-repulsion.png?v=tpAoc2U6_2Ml49zBHqmkkSbb7jugL95LSz6XYYjGIhc\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.3-latents-repulsion.png?v=tpAoc2U6_2Ml49zBHqmkkSbb7jugL95LSz6XYYjGIhc\" alt=\"Three spherical plots, titled &quot;Latents · repulsion&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where &quot;red&quot; should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: &quot;Red&quot; and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to &quot;red&quot;, which roughly agree in saturation but differ significantly in tone and hue.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents · repulsion\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: \"Red\" and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to \"red\", which roughly agree in saturation but differ significantly in tone and hue."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d, ConicalAnnotation\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, interventions, x_rgb, 'bottleneck')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-repulsion.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: \"Red\" and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to \"red\", which roughly agree in saturation but differ significantly in tone and hue.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · repulsion',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "            annotations=[\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - repulsion.mapper.a),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                    dashes=theme.val((8, 8), dark=(4, 4)),\n",
    "                    gapcolor=theme.val('#fff4', dark='#0004'),\n",
    "                ),\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - repulsion.mapper.b),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b5643",
   "metadata": {},
   "source": [
    "Like in 2.2, red colors have all been pushed away from the intervened-on concept vector, and have formed a ring around it. The effectiveness of this intervention seems similar to the previous model (which lacked explicit normalization). That's surprising: I would have expected repulsion to be more sensitive to deviations from unit norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17177769",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "1. Explicitly normalizing the bottleneck activations massively improves the reconstruction loss: an order of magnitude better performance with an order of magnitude fewer training steps. The structure of latent space is also much smoother and more regular.\n",
    "2. Removing the sigmoid function from the decoder output helps this model to reproduce colors better, and marginally improves the structure of latent space.\n",
    "\n",
    "# Next steps\n",
    "\n",
    "See whether performance improves further if some regularizers are run after the explicit normalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

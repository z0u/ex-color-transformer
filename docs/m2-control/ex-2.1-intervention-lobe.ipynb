{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8817a226",
   "metadata": {},
   "source": [
    "# Experiment 2.1: Intervention lobes\n",
    "\n",
    "In this series of experiments, we shall explore the effects of intervening on latent activations. Having structured the latent space (see Ex 1.x), it should just be a matter of transforming latent embeddings that are closely aligned to the anchored concepts.\n",
    "\n",
    "We draw inspiration from shaders in computer graphics: BSDFs compute the output energy given: 1. an input light direction, and 2. the viewing direction, relative to the surface normal. Our interventions are similar: we have 1. a subject concept vector, and 2. activation vectors. If we treat the subject vector as analogous to a light source and acivation vectors as analogous to viewing directions, we may build on a wealth of established techniques.\n",
    "\n",
    "Here we define our intervention as a BSDF-like function:\n",
    "\n",
    "$$e' = f(s,e)$$\n",
    "\n",
    "Where $e$ is an embedding vector, $s$ is the subject, and $e'$ is the modified embedding. In fact $s$ need not be a (directional) vector; it could be other geometric features of our embedding space, such as a subspace defined by multiple basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7e501f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_id = '2.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819dbdf6",
   "metadata": {},
   "source": [
    "### Intervention function sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ab9aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol, Sequence\n",
    "\n",
    "import torch\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor\n",
    "\n",
    "from ex_color.intervention.intervention import ConstAnnotation, Intervention\n",
    "\n",
    "\n",
    "def sample_idf(\n",
    "    idf: Intervention, n=360, *, eps=0.0, include_end=False\n",
    ") -> tuple[NDArray, NDArray, NDArray, tuple[str, NDArray]]:\n",
    "    # Input angles θ_in: [0, 2π)\n",
    "    thetas_in: Tensor = torch.linspace(eps, 2 * torch.pi - eps, steps=n + 1, dtype=torch.float32)\n",
    "    if not include_end:\n",
    "        thetas_in = thetas_in[:-1]\n",
    "\n",
    "    # Unit circle directions, shape [n, 2]\n",
    "    unit: Tensor = torch.stack((torch.cos(thetas_in), torch.sin(thetas_in)), dim=-1)\n",
    "\n",
    "    # Apply intervention (idf expects Tensors); disable grad for safety\n",
    "    with torch.no_grad():\n",
    "        out: Tensor = idf(unit)  # [n, 2]\n",
    "        annotation = idf.annotate_activations(unit)  # [n]\n",
    "\n",
    "    # Convert outputs to polar coordinates\n",
    "    y, x = out[..., 1], out[..., 0]\n",
    "    theta_out = torch.atan2(y, x)  # [-π, π]\n",
    "    # Wrap angles to be positive\n",
    "    theta_out = (theta_out + 2 * torch.pi) % (2 * torch.pi)  # [0, 2π]\n",
    "    r_out = torch.linalg.norm(out, dim=-1)\n",
    "\n",
    "    return (\n",
    "        theta_out.detach().cpu().numpy(),\n",
    "        r_out.detach().cpu().numpy(),\n",
    "        thetas_in.detach().cpu().numpy(),\n",
    "        (annotation.name, annotation.values.detach().cpu().numpy()),\n",
    "    )\n",
    "\n",
    "\n",
    "class Mapper(Protocol):\n",
    "    def __call__(self, alignment: Tensor) -> Tensor: ...\n",
    "\n",
    "    @property\n",
    "    def annotations(self) -> Sequence[ConstAnnotation]: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d72d23",
   "metadata": {},
   "source": [
    "### Special chart series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1a4cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor\n",
    "\n",
    "from ex_color.intervention.intervention import Intervention\n",
    "\n",
    "from typing import Literal\n",
    "from matplotlib.patheffects import SimpleLineShadow, Normal\n",
    "\n",
    "\n",
    "def wrapped_angular_diff(a: float, b: float) -> float:\n",
    "    \"\"\"Compute the angular difference between two angles a and b, wrapping around at 2π.\"\"\"\n",
    "    # Ensure 0 is considered close to 2pi\n",
    "    diff = (b - a) % (2 * np.pi)\n",
    "    return min(diff, 2 * np.pi - diff)\n",
    "\n",
    "\n",
    "def filled_series(\n",
    "    ax: Axes,\n",
    "    xs: NDArray,\n",
    "    ys: NDArray,\n",
    "    *,\n",
    "    color: str | None,\n",
    "    alpha=0.3,\n",
    "    close: Literal['auto', 'always'] = 'auto',\n",
    "    **kwargs,\n",
    "):\n",
    "    span_x = wrapped_angular_diff(xs[0], xs[-1])\n",
    "    _close = close == 'always' or isinstance(ax, PolarAxes) and span_x < radians(2)\n",
    "\n",
    "    ax.fill(\n",
    "        np.concatenate([xs, [xs[0]]]) if _close else np.concatenate([[0], xs, [0]]),\n",
    "        np.concatenate([ys, [ys[0]]]) if _close else np.concatenate([[0], ys, [0]]),\n",
    "        color=color,\n",
    "        alpha=alpha,\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.concatenate([xs, [xs[0]]]) if _close else xs,\n",
    "        np.concatenate([ys, [ys[0]]]) if _close else ys,\n",
    "        color=color,\n",
    "        path_effects=[\n",
    "            SimpleLineShadow((0, 0), linewidth=3, alpha=0.1),\n",
    "            SimpleLineShadow((0, 0), linewidth=6, alpha=0.05),\n",
    "            SimpleLineShadow((0, 0), linewidth=9, alpha=0.025),\n",
    "            Normal(),\n",
    "        ],\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "Shape = Literal['line', 'chord']\n",
    "\n",
    "\n",
    "def diff_series(\n",
    "    ax: Axes,\n",
    "    xs1: NDArray,\n",
    "    xs2: NDArray,\n",
    "    ys1: NDArray,\n",
    "    ys2: NDArray,\n",
    "    *,\n",
    "    shape: Shape,\n",
    "    label: str | None = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Draw line segments between two series of points (xs1, ys1) and (xs2, ys2).\"\"\"\n",
    "    # Split kwargs\n",
    "    marker_kwargs = {k: v for k, v in kwargs.items() if k.startswith('marker')}\n",
    "    other_kwargs = {k: v for k, v in kwargs.items() if not k.startswith('marker')}\n",
    "\n",
    "    # Draw line segments between series 1 and 2\n",
    "    for x1, x2, y1, y2 in zip(xs1, xs2, ys1, ys2, strict=True):\n",
    "        if np.abs(x2 - x1) > np.pi:\n",
    "            # Take the shortest path around the circle\n",
    "            x1 += 2 * np.pi\n",
    "        if shape == 'chord':\n",
    "            # Draw a curve, like a chord diagram, to make it easier to see where the points go\n",
    "            # Without this, rotations are hard to interpret because the lines have similar angles\n",
    "            curve_length_x = wrapped_angular_diff(x1, x2)\n",
    "            curve_power = 2.2\n",
    "            curve_strength = 0.97 * (curve_length_x / np.pi) + 0.03\n",
    "            xs = np.linspace(x1, x2, 100)\n",
    "            ys = np.linspace(y1, y2, 100)\n",
    "            # pull ys down in the middle\n",
    "            yfrac = np.concatenate([np.linspace(1, 0, 50), np.linspace(0, 1, 50)])\n",
    "            yfrac **= curve_power\n",
    "            ys *= yfrac * curve_strength + 1 - curve_strength\n",
    "        else:\n",
    "            xs = [x1, x2]\n",
    "            ys = [y1, y2]\n",
    "        ax.plot(xs, ys, zorder=0, **other_kwargs)\n",
    "\n",
    "    # Draw markers\n",
    "    # # Starts\n",
    "    # ax.plot(xs1, ys1, linestyle='', **marker_kwargs)\n",
    "    # Ends\n",
    "    ax.plot(xs2, ys2, linestyle='', **marker_kwargs)\n",
    "\n",
    "    # Only add the label once\n",
    "    if label:\n",
    "        ax.plot([], [], label=label, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae07f9",
   "metadata": {},
   "source": [
    "### Polar lobe charts\n",
    "\n",
    "These charts show a 2D slice of functions with a polar projection. This helps to visualize the _shape_ of the intervention, although it's a bit hard to interpret the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "350ad130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from math import pi, acos\n",
    "\n",
    "NEON = ['hotpink', 'orange', 'limegreen', 'pink', 'aqua', 'yellow']\n",
    "\n",
    "\n",
    "def draw_intervention_slice(ax: Axes | PolarAxes, idf: Intervention):\n",
    "    \"\"\"\n",
    "    Plot a 2D slice of an intervention function on a polar axes.\n",
    "\n",
    "    The angular coordinate corresponds to the direction of a unit input vector.\n",
    "    Two curves are drawn:\n",
    "      - Transformed: the output vector converted to polar (θ_out, r_out)\n",
    "      - Falloff: the magnitude of the intervention plotted against input θ\n",
    "\n",
    "    Args:\n",
    "        ax: A PolarAxes instance to draw into.\n",
    "        idf: The intervention function to plot. Will be called with a tensor of [B,E] where E=2.\n",
    "    \"\"\"\n",
    "    theta_out, r_out, thetas_in, annotation = sample_idf(idf, 360, eps=1e-7)\n",
    "\n",
    "    # Post-intervention activations\n",
    "    filled_series(\n",
    "        ax,\n",
    "        theta_out,\n",
    "        r_out,\n",
    "        color='#1f77b4',\n",
    "        linewidth=2.0,\n",
    "        label='Transformed',\n",
    "        alpha=0.15 if isinstance(ax, PolarAxes) else 0.0,\n",
    "    )\n",
    "\n",
    "    # Magnitude of intervention\n",
    "    filled_series(\n",
    "        ax,\n",
    "        thetas_in,\n",
    "        annotation[1],\n",
    "        color='#ff7f0e',\n",
    "        close='always',\n",
    "        linewidth=2.0,\n",
    "        label=annotation[0],\n",
    "        alpha=0.15 if isinstance(ax, PolarAxes) else 0.0,\n",
    "    )\n",
    "\n",
    "    # Differences\n",
    "    theta_out, r_out, thetas_in, _ = sample_idf(idf, 360 // 10, eps=1e-7, include_end=idf.type != 'linear')\n",
    "    diff_series(\n",
    "        ax,\n",
    "        thetas_in,\n",
    "        theta_out,\n",
    "        np.ones_like(thetas_in),\n",
    "        r_out,\n",
    "        shape='line' if idf.type == 'linear' else 'chord',\n",
    "        color='white',\n",
    "        alpha=0.6,\n",
    "        linewidth=0.5,\n",
    "        marker='o',\n",
    "        markersize=2.0,\n",
    "        markeredgecolor='none',\n",
    "        markerfacecolor='white',\n",
    "        label='Offset',\n",
    "    )\n",
    "\n",
    "    for annot, color in zip(idf.annotations, cycle(NEON), strict=False):\n",
    "        if annot.type == 'angular':\n",
    "            cx = acos(annot.value)\n",
    "            ax.axvline(cx, color=color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "            ax.axvline(-cx, color=color, alpha=1.0, linewidth=1, linestyle='--', zorder=0)\n",
    "        else:\n",
    "            cy = annot.value\n",
    "            ax.axhline(cy, color=color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "\n",
    "    if isinstance(ax, PolarAxes):\n",
    "        # Customize polar plot\n",
    "        ax.set_theta_zero_location('N')  # 0° at top (perfect alignment)\n",
    "        # ax.set_thetalim(0, np.pi)  # Only show 0 to π (hemisphere)\n",
    "\n",
    "        # Configure polar grid\n",
    "        ax.set_thetagrids([180], [''])  # One line: opposing (cos sim = -1)\n",
    "        ax.set_rticks([0.0, 1.0])  # Just the outer circle\n",
    "\n",
    "        # Set radial limit to comfortably contain all data and the unit radius\n",
    "        max_r = max(r_out.max(), annotation[1].max(), 1.0)\n",
    "        ax.set_rmax(max(1.0, max_r) * 1.1)\n",
    "\n",
    "    else:\n",
    "        ax.set_xlim(0, np.pi)\n",
    "        ax.set_ylim(0, max(r_out.max(), annotation[1].max(), 1.0) * 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911dcb6",
   "metadata": {},
   "source": [
    "### Linear charts\n",
    "\n",
    "These charts show the effects of the intervention as well. The input to the intervention is the alignment with the concept vector — so we'll use that as the x-axis. The choice of y-axis depends on the type of the intervention:\n",
    "\n",
    "- For suppression, it's useful to see the magnitude of the intervention\n",
    "- For repulsion, it's more useful to see the output of the mapping (i.e. the post-intervention alignment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2363a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for linear charts reused across figures\n",
    "from math import cos, pi, sqrt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.patheffects import SimpleLineShadow, Normal\n",
    "\n",
    "\n",
    "def draw_mapping_linear(\n",
    "    ax: Axes,\n",
    "    mapping: Mapper,\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    color: str = '#1f77b4',\n",
    "    color_secondary: str = '#ff7f0e',\n",
    "    show_identity: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw a linear mapping y = f(x) for cosine similarity inputs.\n",
    "\n",
    "    x is cosine similarity in [-1, 1]. y is mapping(x) in [-1, 1].\n",
    "    \"\"\"\n",
    "    x = np.linspace(-1, 1, 400, dtype=np.float32)\n",
    "    xt = torch.from_numpy(x)\n",
    "    with torch.no_grad():\n",
    "        y = mapping(xt).detach().cpu().numpy()\n",
    "\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    setup_cosine_axes(ax, axis='both')\n",
    "\n",
    "    if show_identity:\n",
    "        ax.axline((0, 0), slope=1, color='gray', alpha=0.2, linewidth=1, linestyle='--')\n",
    "\n",
    "    # Fill region between identity and adjusted activations: this is the magnitude of the effect\n",
    "    ax.fill_between(x, x, y, color=color_secondary, alpha=0.15, zorder=0)\n",
    "\n",
    "    ax.plot(\n",
    "        x,\n",
    "        y,\n",
    "        label='activation alignment',\n",
    "        color=color,\n",
    "        linewidth=2,\n",
    "        path_effects=[SimpleLineShadow((0, 0), linewidth=4, alpha=0.5), Normal()],\n",
    "    )\n",
    "\n",
    "    for annot, _color in zip(mapping.annotations, cycle(NEON), strict=False):\n",
    "        # Both axes are angular, so inspect direction\n",
    "        if annot.direction == 'input':\n",
    "            ax.axvline(annot.value, color=_color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "            ax.text(\n",
    "                annot.value + 0.02,\n",
    "                ax.viewLim.ymin + 0.2,\n",
    "                f'{annot.name} = {annot.value:.2g}',\n",
    "                color=_color,\n",
    "                fontsize='x-small',\n",
    "                rotation=90,\n",
    "            )\n",
    "        else:\n",
    "            ax.axhline(annot.value, color=_color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "            ax.text(\n",
    "                ax.viewLim.xmin + 0.2,\n",
    "                annot.value + 0.02,\n",
    "                f'{annot.name} = {annot.value:.2g}',\n",
    "                color=_color,\n",
    "                fontsize='x-small',\n",
    "            )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def draw_suppression_strength(\n",
    "    ax: Axes,\n",
    "    falloff: Mapper,\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    color: str = '#ff7f0e',\n",
    "    color_secondary: str = '#1f77b4',\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw suppression amount vs cosine similarity.\n",
    "\n",
    "    x: cosine similarity in [-1, 1]\n",
    "    y: suppression amount in [0, 1] computed as falloff(alignment),\n",
    "       where alignment = max(0, x) for unidirectional suppression.\n",
    "    \"\"\"\n",
    "    x = np.linspace(-1, 1, 400, dtype=np.float32)\n",
    "    alignment = np.clip(x, 0.0, 1.0).astype(np.float32)  # Only positive alignment contributes\n",
    "    xt = torch.from_numpy(alignment)\n",
    "    with torch.no_grad():\n",
    "        y = falloff(xt).detach().cpu().numpy()\n",
    "\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(0, max(1.0, float(np.max(y)) * 1.05))\n",
    "    setup_cosine_axes(ax, axis='x')\n",
    "    ax.set_ylabel('Suppression amount', fontsize='small', labelpad=10)\n",
    "\n",
    "    # Fill region above: this is the residual activation magnitude\n",
    "    ax.fill_between(x, np.ones_like(x), y, color=color_secondary, alpha=0.15, zorder=0)\n",
    "\n",
    "    # Fill region below: this is the strength of the effect (mirrors the filled region in the polar plots)\n",
    "    ax.fill_between(x, np.zeros_like(x), y, color=color, alpha=0.15, zorder=0)\n",
    "\n",
    "    ax.plot(\n",
    "        x,\n",
    "        y,\n",
    "        label='amount',\n",
    "        color=color,\n",
    "        linewidth=2,\n",
    "        path_effects=[SimpleLineShadow((0, 0), linewidth=4, alpha=0.5), Normal()],\n",
    "    )\n",
    "\n",
    "    # Threshold annotation for bounded falloffs defined over alignment\n",
    "\n",
    "    for annot, _color in zip(falloff.annotations, cycle(NEON), strict=False):\n",
    "        # One angular and one linear axis, so inspect type\n",
    "        if annot.type != 'linear':\n",
    "            ax.axvline(annot.value, color=_color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "            ax.text(\n",
    "                annot.value + 0.02,\n",
    "                ax.viewLim.ymin + 0.2,\n",
    "                f'{annot.name} = {annot.value:.2g}',\n",
    "                color=_color,\n",
    "                fontsize='x-small',\n",
    "                rotation=90,\n",
    "            )\n",
    "        else:\n",
    "            ax.axhline(annot.value, color=_color, alpha=1.0, linewidth=1, linestyle='--', label=annot.name, zorder=0)\n",
    "            ax.text(\n",
    "                ax.viewLim.xmin + 0.2,\n",
    "                annot.value + 0.02,\n",
    "                f'{annot.name} = {annot.value:.2g}',\n",
    "                color=_color,\n",
    "                fontsize='x-small',\n",
    "            )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def setup_cosine_axes(ax: Axes, axis: str = 'both') -> None:\n",
    "    \"\"\"\n",
    "    Set cosine ticks/labels on axes for readability.\n",
    "\n",
    "    axis: 'x' | 'y' | 'both'\n",
    "    \"\"\"\n",
    "    # Major ticks at +-1, +-cos(30), +-cos(60), 0\n",
    "    cos_values = np.array([-1, -cos(pi / 6), -cos(pi / 3), 0, cos(pi / 3), cos(pi / 6), 1.0])\n",
    "    xlabels = np.array(['-1\\nopposing', '', '', '0\\northogonal', '', '', '1\\naligned'])\n",
    "    ylabels = np.array(['-1', '', '', '0', '', '', '1'])\n",
    "\n",
    "    if axis in ('x', 'both'):\n",
    "        ax.set_xticks(cos_values)\n",
    "        ax.set_xticklabels(xlabels, fontsize='x-small')\n",
    "        ax.set_xlabel('Cosine similarity (angle from subject)', fontsize='small', labelpad=10)\n",
    "\n",
    "    if axis in ('y', 'both'):\n",
    "        ax.set_yticks(cos_values)\n",
    "        ax.set_yticklabels(ylabels, fontsize='x-small')\n",
    "        ax.set_ylabel('Output cosine similarity', fontsize='small', labelpad=10)\n",
    "\n",
    "    # Minor ticks at every 10 degrees\n",
    "    cos_minor = np.cos(np.arange(0, 91, 10) * np.pi / 180)\n",
    "    cos_minor = np.concatenate([-cos_minor[:-1], cos_minor])\n",
    "    if axis in ('x', 'both'):\n",
    "        ax.set_xticks(cos_minor, minor=True)\n",
    "    if axis in ('y', 'both'):\n",
    "        ax.set_yticks(cos_minor, minor=True)\n",
    "\n",
    "    ax.grid(True, which='major', alpha=0.1)\n",
    "\n",
    "\n",
    "def draw_bezier_handle(ax: Axes, cp1: Tensor, cp2: Tensor, *, color: str, **kwargs):\n",
    "    cx, cy = zip(cp1, cp2, strict=True)\n",
    "    ax.plot(\n",
    "        cx,\n",
    "        cy,\n",
    "        color=color,\n",
    "        linewidth=1.5,\n",
    "        zorder=0,\n",
    "        **kwargs,\n",
    "    )\n",
    "    ax.plot(\n",
    "        cx,\n",
    "        cy,\n",
    "        color=color,\n",
    "        linestyle=' ',\n",
    "        marker='o',\n",
    "        markersize=4,\n",
    "        markerfacecolor='black',\n",
    "        markeredgewidth=1.2,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fa933",
   "metadata": {},
   "source": [
    "## Suppression\n",
    "\n",
    "This type of intervention is used to reduce the **magnitude** of embeddings that are aligned with a concept vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b6ba645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotated_types import Ge, Le\n",
    "from typing import Annotated, Sequence, override\n",
    "\n",
    "from pydantic import validate_call\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from ex_color.intervention.intervention import ConstAnnotation, Intervention, VarAnnotation\n",
    "\n",
    "\n",
    "class Bounded:\n",
    "    @validate_call(config={'arbitrary_types_allowed': True})\n",
    "    def __init__(\n",
    "        self,\n",
    "        a: Annotated[float, [Ge(0), Le(1)]],\n",
    "        b: Annotated[float, [Ge(0), Le(1)]],\n",
    "        power: float = 1.0,\n",
    "        eps=1e-8,\n",
    "    ):\n",
    "        assert a < b, 'a must be less than b for Bounded falloff'\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.power = power\n",
    "        self.eps = eps\n",
    "\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        if self.a > 1 - self.eps:\n",
    "            return alignment\n",
    "\n",
    "        shifted = (alignment - self.a) / (1 - self.a)\n",
    "        shifted = shifted**self.power * (self.b)\n",
    "        return torch.where(alignment > self.a, shifted, torch.zeros_like(alignment))\n",
    "\n",
    "    @property\n",
    "    def annotations(self) -> Sequence[ConstAnnotation]:\n",
    "        return [\n",
    "            ConstAnnotation('input', 'angular', 'start', self.a),\n",
    "            ConstAnnotation('output', 'linear', 'strength', self.b),\n",
    "        ]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.a:.2g}, {self.b:.2g}, {self.power:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        exp = f'd^{self.power:.2g}' if self.power != 1.0 else 'd'\n",
    "        return f'{exp} | d>{self.a:.2g}, 1→{self.b:.2g}'\n",
    "\n",
    "\n",
    "class Suppression(Intervention):\n",
    "    type = 'linear'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        concept_vector: Tensor,  # Embedding to suppress [E] (unit norm)\n",
    "        falloff: Bounded,  # Function to calculate strength of suppression\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Repel activations away from a concept vector by rotating in their shared plane.\n",
    "\n",
    "        Returns:\n",
    "            Rotated activations with unit norm, shape [B, E].\n",
    "        \"\"\"\n",
    "        super().__init__(concept_vector)\n",
    "        self.falloff = falloff\n",
    "\n",
    "    @override\n",
    "    def dist(self, activations: Tensor) -> Tensor:\n",
    "        dots = torch.sum(activations * self.concept_vector[None, :], dim=1)  # [B]\n",
    "        return dots.clamp(min=0, max=1)\n",
    "\n",
    "    def gate(self, activations: Tensor) -> Tensor:\n",
    "        return self.falloff(self.dist(activations))\n",
    "\n",
    "    @override\n",
    "    def __call__(self, activations: Tensor) -> Tensor:\n",
    "        gate = self.gate(activations)\n",
    "        p = torch.einsum('b...e,e->b...', activations, self.concept_vector)\n",
    "\n",
    "        return activations - torch.einsum('b...,e->b...e', gate * p, self.concept_vector)\n",
    "\n",
    "    @property\n",
    "    @override\n",
    "    def annotations(self):\n",
    "        return self.falloff.annotations\n",
    "\n",
    "    @override\n",
    "    def annotate_activations(self, activations: Tensor) -> VarAnnotation:\n",
    "        return VarAnnotation('strength', self.gate(activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d390d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"large-assets/ex-2.1-suppression.png?v=zZdSxKufSODnWNhSackV10pNdxgxSEC-rR8ZFFdrS18\" alt=\"Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the &#x27;subject&#x27;) is always &#x27;up&#x27;, so the orange &#x27;magnitude&#x27; lobes are also oriented upwards. The blue &#x27;transformed&#x27; lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention.\" style=\"max-width: 100%;\" />"
      ],
      "text/plain": [
       "Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import cos, pi\n",
    "from typing import cast, override\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from pydantic import validate_call\n",
    "\n",
    "from utils.nb import displayer_img\n",
    "from utils.plt import configure_matplotlib\n",
    "\n",
    "configure_matplotlib()\n",
    "\n",
    "\n",
    "falloffs = [\n",
    "    Bounded(0, 0.5),\n",
    "    Bounded(cos(pi / 3), cos(pi / 6)),\n",
    "    Bounded(0, 1, power=2),\n",
    "    Bounded(cos(pi / 3), cos(pi / 6), power=2),\n",
    "]\n",
    "\n",
    "\n",
    "with displayer_img(\n",
    "    f'large-assets/ex-{nb_id}-suppression.png',\n",
    "    alt_text=\"Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention.\",\n",
    ") as show:\n",
    "    # Two rows: polar slices (top) and linear suppression amount (bottom)\n",
    "    n = len(falloffs)\n",
    "    fig = plt.figure(figsize=(1 + 4.5 * n, 8.5), constrained_layout=True)\n",
    "\n",
    "    axes = []\n",
    "    linear_axes = []\n",
    "    lax = None\n",
    "    for i, mapper in enumerate(falloffs):\n",
    "        ax = cast(PolarAxes, fig.add_subplot(2, n, i + 1, axes_class=PolarAxes))\n",
    "        ax.spines['polar'].set_color(c='gray')\n",
    "        ax.grid(True, color='#444', linewidth=0.5)\n",
    "\n",
    "        idf = Suppression(\n",
    "            torch.tensor([1, 0], dtype=torch.float32),  # North\n",
    "            mapper,\n",
    "        )\n",
    "        draw_intervention_slice(ax, idf)\n",
    "        ax.set_title(str(idf.falloff), pad=15)\n",
    "        ax.tick_params(labelleft=False)  # The y-axis is actually the radial axis\n",
    "        ax.spines['polar'].set_visible(False)\n",
    "        axes.append(ax)\n",
    "\n",
    "        # Linear suppression-strength chart\n",
    "        lax = fig.add_subplot(2, n, n + i + 1, sharey=lax)\n",
    "        draw_suppression_strength(lax, mapper, title='amount vs cos(θ)')\n",
    "        lax.set_aspect('equal')\n",
    "        lax.set_adjustable('box')\n",
    "        if i > 0:\n",
    "            lax.tick_params(labelleft=False)\n",
    "            lax.set_ylabel('')\n",
    "            lax.set_xlabel('')\n",
    "        linear_axes.append(lax)\n",
    "\n",
    "    # Single legend for all polar axes\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    legend = fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='lower center',\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.05),\n",
    "        bbox_transform=fig.transFigure,\n",
    "        fontsize='medium',\n",
    "    )\n",
    "\n",
    "    fig.suptitle('Intervention lobes: Suppression')\n",
    "\n",
    "    show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a78bc0",
   "metadata": {},
   "source": [
    "## Repulsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2ab0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex_color.intervention.intervention import ConstAnnotation\n",
    "\n",
    "\n",
    "from annotated_types import Ge, Gt, Le, Lt\n",
    "from typing import Annotated\n",
    "\n",
    "\n",
    "class LinearMapper(Mapper):\n",
    "    @validate_call(config={'arbitrary_types_allowed': True})\n",
    "    def __init__(\n",
    "        self,\n",
    "        a: Annotated[float, [Ge(0), Lt(1)]],\n",
    "        b: Annotated[float, [Gt(0), Le(1)]],\n",
    "        eps=1e-8,\n",
    "    ):\n",
    "        assert a < b\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.eps = eps\n",
    "\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:  # alignment is a batch, shape [B]\n",
    "        shifted = (alignment - self.a) / (1 - self.a)\n",
    "        shifted = shifted * (self.b - self.a) + self.a\n",
    "        return torch.where(alignment > self.a, shifted, alignment)\n",
    "\n",
    "    @property\n",
    "    def annotations(self):\n",
    "        return [\n",
    "            ConstAnnotation('input', 'angular', 'start', self.a),\n",
    "            ConstAnnotation('output', 'angular', 'end', self.b),\n",
    "        ]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.a:.2g}, {self.b:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'd>{self.a:.2g}, 1→{self.b:.2g}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a8c3a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class BezierMapper(Mapper):\n",
    "    @validate_call\n",
    "    def __init__(\n",
    "        self,\n",
    "        a: Annotated[float, [Ge(0), Lt(1)]],\n",
    "        b: Annotated[float, [Gt(0), Le(1)]],\n",
    "        start_slope: float = 1.0,  # Aligned with unmapped leadup\n",
    "        end_slope: float = 0.0,  # Flat\n",
    "        control_distance: float = 1 / sqrt(2),  # Relative to intersection point\n",
    "    ):\n",
    "        assert a < b <= 1\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "        # Find intersection of the two tangent lines\n",
    "        # Line 1: y - a = start_slope * (x - a)  =>  y = start_slope * (x - a) + a\n",
    "        # Line 2: y - b = end_slope * (x - 1)    =>  y = end_slope * (x - 1) + b\n",
    "        # At intersection: start_slope * (x - a) + a = end_slope * (x - 1) + b\n",
    "\n",
    "        if abs(start_slope - end_slope) < 1e-8:\n",
    "            # Parallel lines - use midpoint as fallback\n",
    "            intersection_x = (a + 1) / 2\n",
    "            intersection_y = (a + b) / 2\n",
    "        else:\n",
    "            intersection_x = (a * (start_slope - 1) + b - end_slope) / (start_slope - end_slope)\n",
    "            intersection_y = start_slope * (intersection_x - a) + a\n",
    "\n",
    "        intersection = torch.tensor([intersection_x, intersection_y], dtype=torch.float32)\n",
    "\n",
    "        # Define the 4 control points for cubic Bézier\n",
    "        self.P0 = torch.tensor([a, a], dtype=torch.float32)\n",
    "        self.P3 = torch.tensor([1.0, b], dtype=torch.float32)\n",
    "\n",
    "        # P1: distance from P0 towards intersection, scaled by control_distance\n",
    "        direction_to_intersection = intersection - self.P0\n",
    "        self.P1 = self.P0 + control_distance * direction_to_intersection\n",
    "\n",
    "        # P2: distance from P3 towards intersection, scaled by control_distance\n",
    "        direction_to_intersection = intersection - self.P3\n",
    "        self.P2 = self.P3 + control_distance * direction_to_intersection\n",
    "\n",
    "    def bezier_point(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Evaluate cubic Bézier curve at parameter t\"\"\"\n",
    "        one_minus_t = 1 - t\n",
    "\n",
    "        term0 = (one_minus_t**3)[:, None] * self.P0[None, :]\n",
    "        term1 = (3 * one_minus_t**2 * t)[:, None] * self.P1[None, :]\n",
    "        term2 = (3 * one_minus_t * t**2)[:, None] * self.P2[None, :]\n",
    "        term3 = (t**3)[:, None] * self.P3[None, :]\n",
    "\n",
    "        return term0 + term1 + term2 + term3\n",
    "\n",
    "    def bezier_x(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Get x-coordinate of Bézier curve at parameter t\"\"\"\n",
    "        return self.bezier_point(t)[:, 0]  # Changed from [..., 0]\n",
    "\n",
    "    def bezier_y(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Get y-coordinate of Bézier curve at parameter t\"\"\"\n",
    "        return self.bezier_point(t)[:, 1]  # Changed from [..., 1]\n",
    "\n",
    "    def solve_for_t(self, x: Tensor, max_iters: int = 10) -> Tensor:\n",
    "        \"\"\"Solve for parameter t such that bezier_x(t) = x using Newton's method\"\"\"\n",
    "        # Initial guess: linear interpolation\n",
    "        t = (x - self.a) / (1 - self.a)\n",
    "        t = torch.clamp(t, 0.01, 0.99)  # Avoid endpoints\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "            # Newton step: t_new = t - f(t)/f'(t)\n",
    "            # where f(t) = bezier_x(t) - target_x\n",
    "\n",
    "            # Enable gradients for automatic differentiation\n",
    "            t_var = t.clone().requires_grad_(True)\n",
    "            x_pred = self.bezier_x(t_var)\n",
    "            error = x_pred - x\n",
    "\n",
    "            # Compute derivative dx/dt\n",
    "            dx_dt = torch.autograd.grad(x_pred.sum(), t_var, create_graph=False)[0]\n",
    "\n",
    "            # Newton update (be careful with division by zero)\n",
    "            dt = error / (dx_dt + 1e-8)\n",
    "            t = t - dt\n",
    "            t = torch.clamp(t, 0.0, 1.0)\n",
    "\n",
    "            # Check convergence\n",
    "            if torch.max(torch.abs(error)) < 1e-6:\n",
    "                break\n",
    "\n",
    "        return t\n",
    "\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        result = alignment.clone()\n",
    "\n",
    "        # Only apply Bézier mapping for alignment > a\n",
    "        mask = alignment > self.a\n",
    "        if mask.any():\n",
    "            x_vals = alignment[mask]\n",
    "\n",
    "            # Solve for t parameters\n",
    "            t_vals = self.solve_for_t(x_vals)\n",
    "\n",
    "            # Get corresponding y values\n",
    "            y_vals = self.bezier_y(t_vals)\n",
    "\n",
    "            result[mask] = y_vals\n",
    "\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def annotations(self):\n",
    "        return [\n",
    "            ConstAnnotation('input', 'angular', 'start', self.a),\n",
    "            ConstAnnotation('output', 'angular', 'end', self.b),\n",
    "        ]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'BezierMapper(a={self.a:.2g}, b={self.b:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Bézier[{self.a:.2g}→{self.b:.2g}]'\n",
    "\n",
    "\n",
    "class FastBezierMapper(BezierMapper):\n",
    "    def __init__(self, *args, lookup_resolution: int = 1000, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Precompute lookup table\n",
    "        t_vals = torch.linspace(0, 1, lookup_resolution, dtype=torch.float32)\n",
    "        bezier_points = self.bezier_point(t_vals)\n",
    "\n",
    "        # Ensure contiguous storage to avoid searchsorted warning\n",
    "        self.x_lookup = bezier_points[:, 0].contiguous()  # x coordinates\n",
    "        self.y_lookup = bezier_points[:, 1].contiguous()  # y coordinates\n",
    "\n",
    "    def interpolate_1d(self, x_query: Tensor) -> Tensor:\n",
    "        \"\"\"1D linear interpolation using lookup table\"\"\"\n",
    "        # Find insertion points for x_query in x_lookup\n",
    "        indices = torch.searchsorted(self.x_lookup, x_query, right=False)\n",
    "\n",
    "        # Clamp indices to valid range\n",
    "        indices = torch.clamp(indices, 1, len(self.x_lookup) - 1)\n",
    "\n",
    "        # Get surrounding points\n",
    "        x0 = self.x_lookup[indices - 1]\n",
    "        x1 = self.x_lookup[indices]\n",
    "        y0 = self.y_lookup[indices - 1]\n",
    "        y1 = self.y_lookup[indices]\n",
    "\n",
    "        # Linear interpolation: y = y0 + (y1 - y0) * (x - x0) / (x1 - x0)\n",
    "        t = (x_query - x0) / (x1 - x0 + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "        y_interp = y0 + t * (y1 - y0)\n",
    "\n",
    "        return y_interp\n",
    "\n",
    "    @override\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        result = alignment.clone()\n",
    "        mask = alignment > self.a\n",
    "\n",
    "        if mask.any():\n",
    "            x_vals = alignment[mask]\n",
    "\n",
    "            # Use interpolation on lookup table instead of Newton's method\n",
    "            y_vals = self.interpolate_1d(x_vals)\n",
    "\n",
    "            result[mask] = y_vals\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8e2ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import override\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from ex_color.intervention.intervention import Intervention\n",
    "\n",
    "\n",
    "class Repulsion(Intervention):\n",
    "    type = 'rotational'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        concept_vector: Tensor,  # Embedding to steer away from [E] (unit norm)\n",
    "        mapper: Mapper,  # Function to recalculate dot products to determine rotation of activations\n",
    "        eps: float = 1e-8,  # Numerical stability threshold\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Repel activations away from subject vector by rotating in their shared plane.\n",
    "\n",
    "        Returns:\n",
    "            Rotated activations with unit norm, shape [B, E].\n",
    "        \"\"\"\n",
    "        super().__init__(concept_vector)\n",
    "        self.mapper = mapper\n",
    "        self.eps = eps\n",
    "\n",
    "    @override\n",
    "    def dist(self, activations: Tensor) -> Tensor:\n",
    "        dots = torch.sum(activations * self.concept_vector[None, :], dim=1)  # [B]\n",
    "        return torch.clamp(dots, 0, 1)\n",
    "\n",
    "    @override\n",
    "    def __call__(self, activations: Tensor) -> Tensor:\n",
    "        # Calculate original dot products\n",
    "        dots = self.dist(activations)  # [B]\n",
    "\n",
    "        # Scale dot products with falloff function\n",
    "        target_dots = self.mapper(dots)  # [B]\n",
    "\n",
    "        # Decompose into parallel and perpendicular components\n",
    "        v_parallel = dots[:, None] * self.concept_vector[None, :]  # [B, E]\n",
    "        v_perp = activations - v_parallel  # [B, E]\n",
    "\n",
    "        # Get perpendicular unit vectors (handle near-parallel case)\n",
    "        v_perp_norm = torch.norm(v_perp, dim=1, keepdim=True)  # [B, 1]\n",
    "\n",
    "        # For nearly parallel vectors, choose random orthogonal direction\n",
    "        nearly_parallel = (v_perp_norm < self.eps).squeeze()  # [B]\n",
    "\n",
    "        if nearly_parallel.any():\n",
    "            # Generate random orthogonal vectors\n",
    "            random_vecs = torch.randn_like(v_perp[nearly_parallel])\n",
    "            # Make orthogonal to subject using Gram-Schmidt\n",
    "            proj = torch.sum(random_vecs * self.concept_vector[None, :], dim=1, keepdim=True)\n",
    "            random_vecs = random_vecs - proj * self.concept_vector[None, :]\n",
    "            random_vecs = random_vecs / torch.norm(random_vecs, dim=1, keepdim=True)\n",
    "\n",
    "            v_perp[nearly_parallel] = random_vecs\n",
    "            v_perp_norm[nearly_parallel] = 1.0\n",
    "\n",
    "        u_perp = v_perp / v_perp_norm  # [B, E]\n",
    "\n",
    "        # Construct rotated vectors in the (subject, u_perp) plane\n",
    "        target_dots_clamped = torch.clamp(target_dots, -1 + self.eps, 1 - self.eps)\n",
    "        perp_component = torch.sqrt(1 - target_dots_clamped**2)  # [B]\n",
    "\n",
    "        v_rotated = (\n",
    "            target_dots_clamped[:, None] * self.concept_vector[None, :] + perp_component[:, None] * u_perp\n",
    "        )  # [B, E]\n",
    "\n",
    "        # Only apply rotation to vectors with positive original dot product\n",
    "        should_rotate = dots > 0  # [B]\n",
    "        return torch.where(should_rotate[:, None], v_rotated, activations)\n",
    "\n",
    "    @property\n",
    "    @override\n",
    "    def annotations(self):\n",
    "        return self.mapper.annotations\n",
    "\n",
    "    @override\n",
    "    def annotate_activations(self, activations: Tensor) -> VarAnnotation:\n",
    "        dots = self.dist(activations)  # [B]\n",
    "        target_dots = self.mapper(dots)  # [B]\n",
    "        return VarAnnotation('offset', (dots - target_dots).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58fc92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"large-assets/ex-2.1-repulsion.png?v=x3V5mRfQugsd5R8IQfd1gNR0pgIp6eROdQp-1xbBfd4\" alt=\"Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the &#x27;subject&#x27;) is always &#x27;up&#x27;, so the orange &#x27;magnitude&#x27; lobes are also oriented upwards. The blue &#x27;transformed&#x27; lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention.\" style=\"max-width: 100%;\" />"
      ],
      "text/plain": [
       "Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import cos, pi\n",
    "from typing import cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "\n",
    "from utils.plt import configure_matplotlib\n",
    "\n",
    "configure_matplotlib()\n",
    "\n",
    "\n",
    "falloffs: list[Mapper] = [\n",
    "    LinearMapper(0, cos(pi / 3)),\n",
    "    FastBezierMapper(0, cos(pi / 3), end_slope=0.2),\n",
    "    LinearMapper(cos(pi / 3), cos(pi / 6)),\n",
    "    FastBezierMapper(cos(pi / 3), cos(pi / 6), end_slope=0.2),\n",
    "]\n",
    "\n",
    "\n",
    "with displayer_img(\n",
    "    f'large-assets/ex-{nb_id}-repulsion.png',\n",
    "    alt_text=\"Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention.\",\n",
    ") as show:\n",
    "    # Two rows: polar slices (top) and linear mapping (bottom)\n",
    "    n = len(falloffs)\n",
    "    fig = plt.figure(figsize=(1 + 4.5 * n, 10.5), constrained_layout=True)\n",
    "\n",
    "    axes = []\n",
    "    linear_axes = []\n",
    "    lax = None\n",
    "    for i, mapper in enumerate(falloffs):\n",
    "        ax = cast(PolarAxes, fig.add_subplot(2, n, i + 1, axes_class=PolarAxes))\n",
    "        ax.spines['polar'].set_color(c='gray')\n",
    "        ax.grid(True, color='#444', linewidth=0.5)\n",
    "\n",
    "        idf = Repulsion(\n",
    "            torch.tensor([1, 0], dtype=torch.float32),  # North\n",
    "            mapper,\n",
    "        )\n",
    "        draw_intervention_slice(ax, idf)\n",
    "        ax.set_title(str(idf.mapper), pad=15)\n",
    "        ax.tick_params(labelleft=False)  # The y-axis is actually the radial axis\n",
    "        ax.spines['polar'].set_visible(False)\n",
    "        axes.append(ax)\n",
    "\n",
    "        # Linear mapping chart using the same mapping function (\"falloff\" here)\n",
    "        lax = fig.add_subplot(2, n, n + i + 1, sharey=lax)\n",
    "        draw_mapping_linear(lax, mapper, title='mapping')\n",
    "        lax.set_aspect('equal')\n",
    "        if i > 0:\n",
    "            lax.tick_params(labelleft=False)\n",
    "            lax.set_ylabel('')\n",
    "            lax.set_xlabel('')\n",
    "\n",
    "        # Control points overlay\n",
    "        if isinstance(mapper, BezierMapper):\n",
    "            draw_bezier_handle(lax, mapper.P0, mapper.P1, color='hotpink')\n",
    "            draw_bezier_handle(lax, mapper.P2, mapper.P3, color='orange')\n",
    "        linear_axes.append(lax)\n",
    "\n",
    "    # Single legend for all polar axes\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    legend = fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='lower center',\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.05),\n",
    "        bbox_transform=fig.transFigure,\n",
    "        fontsize='medium',\n",
    "    )\n",
    "\n",
    "    fig.suptitle('Intervention lobes: Repulsion')\n",
    "\n",
    "    show(fig)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8817a226",
   "metadata": {},
   "source": [
    "# Experiment 2.1: Intervention lobes\n",
    "\n",
    "In this series of experiments, we shall explore the effects of intervening on latent activations. Having structured the latent space (see Ex 1.x), it should just be a matter of transforming latent embeddings that are closely aligned to the anchored concepts.\n",
    "\n",
    "We draw inspiration from shaders in computer graphics: BSDFs compute the output energy given: 1. an input light direction, and 2. the viewing direction, relative to the surface normal. Our interventions are similar: we have 1. a subject concept vector, and 2. activation vectors. If we treat the subject vector as analogous to a light source and acivation vectors as analogous to viewing directions, we may build on a wealth of established techniques.\n",
    "\n",
    "Here we define our intervention as a BSDF-like function:\n",
    "\n",
    "$$e' = f(s,e)$$\n",
    "\n",
    "Where $e$ is an embedding vector, $s$ is the subject, and $e'$ is the modified embedding. In fact $s$ need not be a (directional) vector; it could be other geometric features of our embedding space, such as a subspace defined by multiple basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e501f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_id = '2.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819dbdf6",
   "metadata": {},
   "source": [
    "### Intervention function sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from numpy.typing import NDArray\n",
    "from torch import Tensor\n",
    "\n",
    "from ex_color.intervention.intervention import Intervention\n",
    "\n",
    "\n",
    "def sample_idf(idf: Intervention, n=360, *, phase=0.0) -> tuple[NDArray, NDArray, NDArray, NDArray]:\n",
    "    # Input angles θ_in: [0, 2π)\n",
    "    thetas_in: Tensor = torch.linspace(phase, 2 * torch.pi + phase, steps=n + 1, dtype=torch.float32)[:-1]\n",
    "\n",
    "    # Unit circle directions, shape [n, 2]\n",
    "    unit: Tensor = torch.stack((torch.cos(thetas_in), torch.sin(thetas_in)), dim=-1)\n",
    "\n",
    "    # Apply intervention (idf expects Tensors); disable grad for safety\n",
    "    with torch.no_grad():\n",
    "        out: Tensor = idf(unit)  # [n, 2]\n",
    "        # Assume the IDF computes effect strength as falloff(dist(x))\n",
    "        r_mag = idf.falloff(idf.dist(unit))  # [n]\n",
    "        # Compute difference of distances between before and after (however the IDF measures distance)\n",
    "        # r_mag = torch.abs(idf.dist(unit) - idf.dist(out)) # [n]\n",
    "\n",
    "    # Convert outputs to polar coordinates\n",
    "    y, x = out[..., 1], out[..., 0]\n",
    "    theta_out = torch.atan2(y, x)  # [-π, π]\n",
    "    # Wrap angles to be positive\n",
    "    theta_out = (theta_out + 2 * torch.pi) % (2 * torch.pi)  # [0, 2π]\n",
    "    r_out = torch.linalg.norm(out, dim=-1)\n",
    "\n",
    "    return (\n",
    "        theta_out.detach().cpu().numpy(),\n",
    "        r_out.detach().cpu().numpy(),\n",
    "        thetas_in.detach().cpu().numpy(),\n",
    "        r_mag.detach().cpu().numpy(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d72d23",
   "metadata": {},
   "source": [
    "### Special chart series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def wrapped_angular_diff(a: float, b: float) -> float:\n",
    "    \"\"\"Compute the angular difference between two angles a and b, wrapping around at 2π.\"\"\"\n",
    "    # Ensure 0 is considered close to 2pi\n",
    "    diff = (b - a) % (2 * np.pi)\n",
    "    return min(diff, 2 * np.pi - diff)\n",
    "\n",
    "\n",
    "def filled_series(ax: Axes, xs: NDArray, ys: NDArray, *, color: str | None, alpha=0.3, **kwargs):\n",
    "    span_x = wrapped_angular_diff(xs[0], xs[-1])\n",
    "    if isinstance(ax, PolarAxes) and span_x < radians(2):\n",
    "        # Close curve\n",
    "        xs = np.concatenate([xs, [xs[0]]])\n",
    "        ys = np.concatenate([ys, [ys[0]]])\n",
    "\n",
    "    ax.fill(\n",
    "        np.concatenate([[0], xs, [0]]),\n",
    "        np.concatenate([[0], ys, [0]]),\n",
    "        color=color,\n",
    "        alpha=alpha,\n",
    "        zorder=0,\n",
    "    )\n",
    "    ax.plot(xs, ys, color=color, **kwargs)\n",
    "\n",
    "\n",
    "Shape = Literal['line', 'chord']\n",
    "\n",
    "\n",
    "def diff_series(\n",
    "    ax: Axes,\n",
    "    xs1: NDArray,\n",
    "    xs2: NDArray,\n",
    "    ys1: NDArray,\n",
    "    ys2: NDArray,\n",
    "    *,\n",
    "    shape: Shape,\n",
    "    label: str | None = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Draw line segments between two series of points (xs1, ys1) and (xs2, ys2).\"\"\"\n",
    "    # Split kwargs\n",
    "    marker_kwargs = {k: v for k, v in kwargs.items() if k.startswith('marker')}\n",
    "    other_kwargs = {k: v for k, v in kwargs.items() if not k.startswith('marker')}\n",
    "\n",
    "    # Draw line segments between series 1 and 2\n",
    "    for x1, x2, y1, y2 in zip(xs1, xs2, ys1, ys2, strict=True):\n",
    "        if np.abs(x2 - x1) > np.pi:\n",
    "            # Take the shortest path around the circle\n",
    "            x1 += 2 * np.pi\n",
    "        if shape == 'chord':\n",
    "            # Draw a curve, like a chord diagram, to make it easier to see where the points go\n",
    "            # Without this, rotations are hard to interpret because the lines have similar angles\n",
    "            curve_length_x = wrapped_angular_diff(x1, x2)\n",
    "            curve_power = 2.2\n",
    "            curve_strength = 0.97 * (curve_length_x / np.pi) + 0.03\n",
    "            xs = np.linspace(x1, x2, 100)\n",
    "            ys = np.linspace(y1, y2, 100)\n",
    "            # pull ys down in the middle\n",
    "            yfrac = np.concatenate([np.linspace(1, 0, 50), np.linspace(0, 1, 50)])\n",
    "            yfrac **= curve_power\n",
    "            ys *= yfrac * curve_strength + 1 - curve_strength\n",
    "        else:\n",
    "            xs = [x1, x2]\n",
    "            ys = [y1, y2]\n",
    "        ax.plot(xs, ys, **other_kwargs)\n",
    "\n",
    "    # Draw markers\n",
    "    # # Starts\n",
    "    # ax.plot(xs1, ys1, linestyle='', **marker_kwargs)\n",
    "    # Ends\n",
    "    ax.plot(xs2, ys2, linestyle='', **marker_kwargs)\n",
    "\n",
    "    # Only add the label once\n",
    "    if label:\n",
    "        ax.plot([], [], label=label, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae07f9",
   "metadata": {},
   "source": [
    "### Polar lobe charts\n",
    "\n",
    "These charts show a 2D slice of functions with a polar projection. This helps to visualize the _shape_ of the intervention, although it's a bit hard to interpret the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350ad130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_intervention_slice(ax: Axes | PolarAxes, idf: Intervention):\n",
    "    \"\"\"\n",
    "    Plot a 2D slice of an intervention function on a polar axes.\n",
    "\n",
    "    The angular coordinate corresponds to the direction of a unit input vector.\n",
    "    Two curves are drawn:\n",
    "      - Transformed: the output vector converted to polar (θ_out, r_out)\n",
    "      - Falloff: the magnitude of the intervention plotted against input θ\n",
    "\n",
    "    Args:\n",
    "        ax: A PolarAxes instance to draw into.\n",
    "        idf: The intervention function to plot. Will be called with a tensor of [B,E] where E=2.\n",
    "    \"\"\"\n",
    "    theta_out, r_out, thetas_in, r_mag = sample_idf(idf, 360, phase=1e-7)\n",
    "\n",
    "    # Plot on polar axes\n",
    "\n",
    "    # Pre-intervention activations\n",
    "    # ax.plot(\n",
    "    #     thetas_in,\n",
    "    #     np.ones_like(thetas_in),\n",
    "    #     color='hotpink',\n",
    "    #     linewidth=1.0,\n",
    "    #     label='Input',\n",
    "    # )\n",
    "\n",
    "    # Post-intervention activations\n",
    "    filled_series(\n",
    "        ax,\n",
    "        theta_out,\n",
    "        r_out,\n",
    "        color='#1f77b4',\n",
    "        linewidth=2.0,\n",
    "        label='Transformed',\n",
    "        alpha=0.3 if isinstance(ax, PolarAxes) else 0.0,\n",
    "    )\n",
    "\n",
    "    # Magnitude of intervention\n",
    "    filled_series(\n",
    "        ax,\n",
    "        thetas_in,\n",
    "        r_mag,\n",
    "        color='#ff7f0e',\n",
    "        linewidth=2.0,\n",
    "        label='Magnitude',\n",
    "        alpha=0.3 if isinstance(ax, PolarAxes) else 0.0,\n",
    "    )\n",
    "\n",
    "    # Differences\n",
    "    theta_out, r_out, thetas_in, _ = sample_idf(idf, 360 // 10)\n",
    "    diff_series(\n",
    "        ax,\n",
    "        thetas_in,\n",
    "        theta_out,\n",
    "        np.ones_like(thetas_in),\n",
    "        r_out,\n",
    "        shape='line' if idf.type == 'linear' else 'chord',\n",
    "        color='white',\n",
    "        alpha=0.6,\n",
    "        linewidth=0.5,\n",
    "        marker='o',\n",
    "        markersize=2.0,\n",
    "        markeredgecolor='none',\n",
    "        markerfacecolor='white',\n",
    "        label='Offset',\n",
    "    )\n",
    "\n",
    "    # Customize polar plot\n",
    "    if isinstance(ax, PolarAxes):\n",
    "        ax.set_theta_zero_location('N')  # 0° at top (perfect alignment)\n",
    "        # ax.set_theta_direction(-1)  # Clockwise\n",
    "        # ax.set_thetalim(0, np.pi)  # Only show 0 to π (hemisphere)\n",
    "\n",
    "        # Add angle labels\n",
    "        ax.set_thetagrids([0, 30, 60, 90, 120, 150, 180], ['', '', '', '', '', '', ''], ha='left')\n",
    "\n",
    "        # Set radial limit to comfortably contain all data and the unit radius\n",
    "        max_r = max(r_out.max(), r_mag.max(), 1.0)\n",
    "        ax.set_rmax(max(1.0, max_r) * 1.1)\n",
    "\n",
    "    else:\n",
    "        ax.set_xlim(0, np.pi)\n",
    "        ax.set_ylim(0, max(r_out.max(), r_mag.max(), 1.0) * 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911dcb6",
   "metadata": {},
   "source": [
    "### Linear charts\n",
    "\n",
    "These charts show the effects of the intervention as well. The input to the intervention is the alignment with the concept vector — so we'll use that as the x-axis. The choice of y-axis depends on the type of the intervention:\n",
    "\n",
    "- For suppression, it's useful to see the magnitude of the intervention\n",
    "- For repulsion, it's more useful to see the output of the mapping (i.e. the post-intervention alignment).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2363a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for linear charts reused across figures\n",
    "from math import cos, pi, sqrt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "\n",
    "def draw_mapping_linear(\n",
    "    ax: Axes,\n",
    "    mapping,  # Callable[[Tensor], Tensor]\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    color: str = 'white',\n",
    "    show_identity: bool = True,\n",
    "    annotate_params: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw a linear mapping y = f(x) for cosine similarity inputs.\n",
    "\n",
    "    x is cosine similarity in [-1, 1]. y is mapping(x) in [-1, 1].\n",
    "    \"\"\"\n",
    "    x = np.linspace(-1, 1, 400, dtype=np.float32)\n",
    "    xt = torch.from_numpy(x)\n",
    "    with torch.no_grad():\n",
    "        y = mapping(xt).detach().cpu().numpy()\n",
    "\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    setup_cosine_axes(ax, axis='both')\n",
    "\n",
    "    if show_identity:\n",
    "        ax.axline((0, 0), slope=1, color='gray', alpha=0.2, linewidth=1, linestyle='--')\n",
    "\n",
    "    ax.plot(x, y, label='activation alignment', color=color, linewidth=2)\n",
    "\n",
    "    # Optional parameter annotations (a vertical, b horizontal) when present\n",
    "    if annotate_params:\n",
    "        a = getattr(mapping, 'a', None)\n",
    "        b = getattr(mapping, 'b', None)\n",
    "        if isinstance(a, (float, int)):\n",
    "            ax.axvline(float(a), color='hotpink', alpha=1.0, linewidth=1, linestyle='--', label='a')\n",
    "            ax.text(\n",
    "                float(a) + 0.02,\n",
    "                ax.viewLim.ymin + 0.2,\n",
    "                f'a = {float(a):.2g}',\n",
    "                color='hotpink',\n",
    "                fontsize='x-small',\n",
    "                rotation=90,\n",
    "            )\n",
    "        if isinstance(b, (float, int)):\n",
    "            ax.axhline(float(b), color='orange', alpha=1.0, linewidth=1, linestyle='--', label='b')\n",
    "            ax.text(\n",
    "                ax.viewLim.xmin + 0.2,\n",
    "                float(b) + 0.02,\n",
    "                f'b = {float(b):.2g}',\n",
    "                color='orange',\n",
    "                fontsize='x-small',\n",
    "            )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def draw_suppression_strength(\n",
    "    ax: Axes,\n",
    "    falloff,  # Callable[[Tensor], Tensor]\n",
    "    *,\n",
    "    title: str | None = None,\n",
    "    color: str = '#ff7f0e',\n",
    "    annotate_threshold: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw suppression amount vs cosine similarity.\n",
    "\n",
    "    x: cosine similarity in [-1, 1]\n",
    "    y: suppression amount in [0, 1] computed as falloff(alignment),\n",
    "       where alignment = max(0, x) for unidirectional suppression.\n",
    "    \"\"\"\n",
    "    x = np.linspace(-1, 1, 400, dtype=np.float32)\n",
    "    alignment = np.clip(x, 0.0, 1.0).astype(np.float32)  # Only positive alignment contributes\n",
    "    xt = torch.from_numpy(alignment)\n",
    "    with torch.no_grad():\n",
    "        y = falloff(xt).detach().cpu().numpy()\n",
    "\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(0, max(1.0, float(np.max(y)) * 1.05))\n",
    "    setup_cosine_axes(ax, axis='x')\n",
    "    ax.set_ylabel('Suppression amount', fontsize='small', labelpad=10)\n",
    "\n",
    "    ax.plot(x, y, label='amount', color=color, linewidth=2)\n",
    "\n",
    "    # Threshold annotation for bounded falloffs defined over alignment\n",
    "    if annotate_threshold:\n",
    "        lower = getattr(falloff, 'lower', None)\n",
    "        if isinstance(lower, (float, int)) and 0 <= float(lower) <= 1:\n",
    "            cx = float(lower)\n",
    "            ax.axvline(cx, color='hotpink', alpha=1.0, linewidth=1, linestyle='--', label='lower')\n",
    "            ax.text(\n",
    "                cx + 0.02,\n",
    "                ax.viewLim.ymin + 0.2,\n",
    "                f'lower = {cx:.2g}',\n",
    "                color='hotpink',\n",
    "                fontsize='x-small',\n",
    "                rotation=90,\n",
    "            )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "\n",
    "def setup_cosine_axes(ax: Axes, axis: str = 'both') -> None:\n",
    "    \"\"\"\n",
    "    Set cosine ticks/labels on axes for readability.\n",
    "\n",
    "    axis: 'x' | 'y' | 'both'\n",
    "    \"\"\"\n",
    "    # Major ticks at +-1, +-cos(30), +-cos(60), 0\n",
    "    cos_values = np.array([-1, -cos(pi / 6), -cos(pi / 3), 0, cos(pi / 3), cos(pi / 6), 1.0])\n",
    "    xlabels = np.array(['-1\\nopposing', '', '', '0\\northogonal', '', '', '1\\naligned'])\n",
    "    ylabels = np.array(['-1', '', '', '0', '', '', '1'])\n",
    "\n",
    "    if axis in ('x', 'both'):\n",
    "        ax.set_xticks(cos_values)\n",
    "        ax.set_xticklabels(xlabels, fontsize='x-small')\n",
    "        ax.set_xlabel('Cosine similarity (angle from subject)', fontsize='small', labelpad=10)\n",
    "\n",
    "    if axis in ('y', 'both'):\n",
    "        ax.set_yticks(cos_values)\n",
    "        ax.set_yticklabels(ylabels, fontsize='x-small')\n",
    "        ax.set_ylabel('Output cosine similarity', fontsize='small', labelpad=10)\n",
    "\n",
    "    # Minor ticks at every 10 degrees\n",
    "    cos_minor = np.cos(np.arange(0, 91, 10) * np.pi / 180)\n",
    "    cos_minor = np.concatenate([-cos_minor[:-1], cos_minor])\n",
    "    if axis in ('x', 'both'):\n",
    "        ax.set_xticks(cos_minor, minor=True)\n",
    "    if axis in ('y', 'both'):\n",
    "        ax.set_yticks(cos_minor, minor=True)\n",
    "\n",
    "    ax.grid(True, which='major', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7fa933",
   "metadata": {},
   "source": [
    "## Suppression\n",
    "\n",
    "This type of intervention is used to reduce the **magnitude** of embeddings that are aligned with a concept vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"large-assets/ex-2.1-suppression.png?v=1aKqYcJALQ5Xanbm1YUHH8mut53oD0V6uL48JNi996w\" alt=\"Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the &#x27;subject&#x27;) is always &#x27;up&#x27;, so the orange &#x27;magnitude&#x27; lobes are also oriented upwards. The blue &#x27;transformed&#x27; lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention.\" style=\"max-width: 100%;\" />"
      ],
      "text/plain": [
       "Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import sin, pi\n",
    "from typing import cast, Annotated, override\n",
    "\n",
    "from annotated_types import Ge, Le\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from pydantic import validate_call\n",
    "\n",
    "from ex_color.intervention.falloff import Falloff, Linear, Power\n",
    "from ex_color.intervention.suppression import Suppression\n",
    "from utils.nb import displayer_img\n",
    "from utils.plt import configure_matplotlib\n",
    "\n",
    "configure_matplotlib()\n",
    "\n",
    "\n",
    "class Bounded(Falloff):\n",
    "    @validate_call(config={'arbitrary_types_allowed': True})\n",
    "    def __init__(\n",
    "        self,\n",
    "        inner_term: Falloff,\n",
    "        lower: Annotated[float, [Ge(0), Le(1)]],\n",
    "        eps=1e-8,\n",
    "    ):\n",
    "        self.inner_term = inner_term\n",
    "        self.lower = lower\n",
    "        self.eps = eps\n",
    "\n",
    "    @override\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        if self.lower < self.eps:\n",
    "            return self.inner_term(alignment)\n",
    "        if self.lower > 1 - self.eps:\n",
    "            return alignment\n",
    "\n",
    "        scale = 1 - self.lower\n",
    "        shifted = (alignment - self.lower) / scale\n",
    "        shifted = self.inner_term(shifted)\n",
    "        return torch.where(alignment > self.lower, shifted, torch.zeros_like(alignment))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.inner_term}, {self.lower:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.inner_term} | d>{self.lower:.2g}'\n",
    "\n",
    "\n",
    "falloffs = [\n",
    "    Linear(0.5),\n",
    "    Bounded(Linear(0.5), sin(pi * 1 / 6)),\n",
    "    Power(2),\n",
    "    Bounded(Power(2), sin(pi * 1 / 6)),\n",
    "]\n",
    "\n",
    "\n",
    "with displayer_img(\n",
    "    f'large-assets/ex-{nb_id}-suppression.png',\n",
    "    alt_text=\"Grid of semicircular polar plots showing the effects of suppression on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a depression in the top, showing that the directions more aligned with the subject are squashed/attenuated by the intervention.\",\n",
    ") as show:\n",
    "    # Two rows: polar slices (top) and linear suppression amount (bottom)\n",
    "    n = len(falloffs)\n",
    "    fig = plt.figure(figsize=(1 + 4.5 * n, 10), constrained_layout=True)\n",
    "\n",
    "    axes = []\n",
    "    linear_axes = []\n",
    "    for i, falloff in enumerate(falloffs):\n",
    "        ax = cast(PolarAxes, fig.add_subplot(2, n, i + 1, axes_class=PolarAxes))\n",
    "        ax.spines['polar'].set_color(c='gray')\n",
    "        ax.grid(True, color='#444', linewidth=0.5)\n",
    "\n",
    "        idf = Suppression(\n",
    "            subject=torch.tensor([1, 0], dtype=torch.float32),  # North\n",
    "            falloff=falloff,\n",
    "            amount=1,\n",
    "            renormalize=False,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        draw_intervention_slice(ax, idf)\n",
    "        ax.set_title(str(idf.falloff), pad=15)\n",
    "        axes.append(ax)\n",
    "\n",
    "        # Linear suppression-strength chart\n",
    "        lax = fig.add_subplot(2, n, n + i + 1)\n",
    "        draw_suppression_strength(lax, falloff, title='amount vs cos(θ)')\n",
    "        linear_axes.append(lax)\n",
    "\n",
    "    # Single legend for all polar axes\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    legend = fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='lower center',\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.05),\n",
    "        bbox_transform=fig.transFigure,\n",
    "        fontsize='medium',\n",
    "    )\n",
    "\n",
    "    fig.suptitle('Intervention lobes: Suppression')\n",
    "\n",
    "    show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a78bc0",
   "metadata": {},
   "source": [
    "## Repulsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58fc92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"large-assets/ex-2.1-repulsion.png?v=-J-TOCeuceKYqdAZU3UQDlErzPb-3dQV5K63c7m4Tfg\" alt=\"Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the &#x27;subject&#x27;) is always &#x27;up&#x27;, so the orange &#x27;magnitude&#x27; lobes are also oriented upwards. The blue &#x27;transformed&#x27; lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention.\" style=\"max-width: 100%;\" />"
      ],
      "text/plain": [
       "Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import sin, pi\n",
    "from typing import cast, Annotated\n",
    "\n",
    "from annotated_types import Ge, Gt, Le, Lt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "\n",
    "from ex_color.intervention.repulsion import Repulsion\n",
    "from utils.plt import configure_matplotlib\n",
    "\n",
    "configure_matplotlib()\n",
    "\n",
    "\n",
    "class Mapped(Falloff):\n",
    "    @validate_call(config={'arbitrary_types_allowed': True})\n",
    "    def __init__(\n",
    "        self,\n",
    "        inner_term: Falloff,\n",
    "        a: Annotated[float, [Ge(0), Lt(1)]],\n",
    "        b: Annotated[float, [Gt(0), Le(1)]],\n",
    "        eps=1e-8,\n",
    "    ):\n",
    "        assert a < b\n",
    "        self.inner_term = inner_term\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.eps = eps\n",
    "\n",
    "    @override\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:  # alignment is a batch, shape [B]\n",
    "        shifted = (alignment - self.a) / (1 - self.a)\n",
    "        shifted = self.inner_term(shifted)\n",
    "        shifted = shifted * (self.b - self.a) + self.a\n",
    "        return torch.where(alignment > self.a, shifted, alignment)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.inner_term}, {self.a:.2g}, {self.b:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.inner_term} | d∈[{self.a:.2g},{self.b:.2g}]'\n",
    "\n",
    "\n",
    "falloffs = [\n",
    "    Linear(0.5),\n",
    "    # Power(2),\n",
    "    Mapped(\n",
    "        Linear(1),\n",
    "        sin(pi * 1 / 6),\n",
    "        sin(pi * 2 / 6),\n",
    "    ),\n",
    "    Mapped(\n",
    "        Power(2.0),\n",
    "        sin(pi * 1 / 6),\n",
    "        sin(pi * 2 / 6),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "with displayer_img(\n",
    "    f'large-assets/ex-{nb_id}-repulsion.png',\n",
    "    alt_text=\"Grid of semicircular polar plots showing the effects of repulsion on activations. Each plot shows two lobes: an orange one indicating the magnitude of the intervention, and a blue one showing the transformed activation space. The direction being intervened on (the 'subject') is always 'up', so the orange 'magnitude' lobes are also oriented upwards. The blue 'transformed' lobes are more circular but have a chunk taken out of the top, showing that the directions more aligned with the subject are rotated/pushed away by the intervention.\",\n",
    ") as show:\n",
    "    # Two rows: polar slices (top) and linear mapping (bottom)\n",
    "    n = len(falloffs)\n",
    "    fig = plt.figure(figsize=(1 + 4.5 * n, 10), constrained_layout=True)\n",
    "\n",
    "    axes = []\n",
    "    linear_axes = []\n",
    "    for i, falloff in enumerate(falloffs):\n",
    "        ax = cast(PolarAxes, fig.add_subplot(2, n, i + 1, axes_class=PolarAxes))\n",
    "        ax.spines['polar'].set_color(c='gray')\n",
    "        ax.grid(True, color='#444', linewidth=0.5)\n",
    "\n",
    "        idf = Repulsion(\n",
    "            subject=torch.tensor([1, 0], dtype=torch.float32),  # North\n",
    "            falloff=falloff,\n",
    "        )\n",
    "        draw_intervention_slice(ax, idf)\n",
    "        ax.set_title(str(idf.falloff), pad=15)\n",
    "        axes.append(ax)\n",
    "\n",
    "        # Linear mapping chart using the same mapping function (\"falloff\" here)\n",
    "        lax = fig.add_subplot(2, n, n + i + 1)\n",
    "        draw_mapping_linear(lax, falloff, title='mapping')\n",
    "        linear_axes.append(lax)\n",
    "\n",
    "    # Single legend for all polar axes\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    legend = fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='lower center',\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.05),\n",
    "        bbox_transform=fig.transFigure,\n",
    "        fontsize='medium',\n",
    "    )\n",
    "\n",
    "    fig.suptitle('Intervention lobes: Repulsion')\n",
    "\n",
    "    show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b84961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"large-assets/ex-2.1-bezier-mapping.png?v=UntMKeUYRLSHx5VmPEKQd9rKcwqIoXUoK5RMckWDPxo\" alt=\"A graph titled &#x27;Mapping function (Bézier)&#x27; showing how input cosine similarity values are transformed by the intervention. The x-axis shows &#x27;Cosine similarity (angle from subject)&#x27; ranging from 180° (opposing) on the left to 0° (aligned) on the right, passing through 90° (orthogonal) in the middle. The y-axis shows &#x27;Output cosine similarity&#x27; with the same angular scale from 180° at bottom to 0° at top. A diagonal gray &#x27;Identity&#x27; line runs from bottom-left to top-right, representing no transformation. Two dashed reference lines mark key parameters: a vertical magenta line &#x27;a&#x27; at approximately 60° and an orange horizontal line &#x27;b&#x27; at approximately 30°. The main white curve labeled &#x27;activation alignment&#x27; follows the identity line until reaching the &#x27;a&#x27; threshold, then smoothly curves to the right, demonstrating how the Bézier function maps highly aligned inputs (near 0°) to the target output value &#x27;b&#x27; (30°). This illustrates the intervention&#x27;s effect: activations below the &#x27;a&#x27; threshold remain unchanged, while those above are smoothly redirected according to the Bézier curve.\" style=\"max-width: 100%;\" />"
      ],
      "text/plain": [
       "A graph titled 'Mapping function (Bézier)' showing how input cosine similarity values are transformed by the intervention. The x-axis shows 'Cosine similarity (angle from subject)' ranging from 180° (opposing) on the left to 0° (aligned) on the right, passing through 90° (orthogonal) in the middle. The y-axis shows 'Output cosine similarity' with the same angular scale from 180° at bottom to 0° at top. A diagonal gray 'Identity' line runs from bottom-left to top-right, representing no transformation. Two dashed reference lines mark key parameters: a vertical magenta line 'a' at approximately 60° and an orange horizontal line 'b' at approximately 30°. The main white curve labeled 'activation alignment' follows the identity line until reaching the 'a' threshold, then smoothly curves to the right, demonstrating how the Bézier function maps highly aligned inputs (near 0°) to the target output value 'b' (30°). This illustrates the intervention's effect: activations below the 'a' threshold remain unchanged, while those above are smoothly redirected according to the Bézier curve."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import cos, pi, sqrt\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class BezierMapper(Falloff):\n",
    "    @validate_call\n",
    "    def __init__(\n",
    "        self,\n",
    "        a: Annotated[float, [Ge(0), Lt(1)]],\n",
    "        b: Annotated[float, [Gt(0), Le(1)]],\n",
    "        start_slope: float = 1.0,  # Aligned with unmapped leadup\n",
    "        end_slope: float = 0.0,  # Flat\n",
    "        control_distance: float = 1 / sqrt(2),  # Relative to intersection point\n",
    "    ):\n",
    "        assert a < b <= 1\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "        # Find intersection of the two tangent lines\n",
    "        # Line 1: y - a = start_slope * (x - a)  =>  y = start_slope * (x - a) + a\n",
    "        # Line 2: y - b = end_slope * (x - 1)    =>  y = end_slope * (x - 1) + b\n",
    "        # At intersection: start_slope * (x - a) + a = end_slope * (x - 1) + b\n",
    "\n",
    "        if abs(start_slope - end_slope) < 1e-8:\n",
    "            # Parallel lines - use midpoint as fallback\n",
    "            intersection_x = (a + 1) / 2\n",
    "            intersection_y = (a + b) / 2\n",
    "        else:\n",
    "            intersection_x = (a * (start_slope - 1) + b - end_slope) / (start_slope - end_slope)\n",
    "            intersection_y = start_slope * (intersection_x - a) + a\n",
    "\n",
    "        intersection = torch.tensor([intersection_x, intersection_y], dtype=torch.float32)\n",
    "\n",
    "        # Define the 4 control points for cubic Bézier\n",
    "        self.P0 = torch.tensor([a, a], dtype=torch.float32)\n",
    "        self.P3 = torch.tensor([1.0, b], dtype=torch.float32)\n",
    "\n",
    "        # P1: distance from P0 towards intersection, scaled by control_distance\n",
    "        direction_to_intersection = intersection - self.P0\n",
    "        self.P1 = self.P0 + control_distance * direction_to_intersection\n",
    "\n",
    "        # P2: distance from P3 towards intersection, scaled by control_distance\n",
    "        direction_to_intersection = intersection - self.P3\n",
    "        self.P2 = self.P3 + control_distance * direction_to_intersection\n",
    "\n",
    "    def bezier_point(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Evaluate cubic Bézier curve at parameter t\"\"\"\n",
    "        one_minus_t = 1 - t\n",
    "\n",
    "        term0 = (one_minus_t**3)[:, None] * self.P0[None, :]\n",
    "        term1 = (3 * one_minus_t**2 * t)[:, None] * self.P1[None, :]\n",
    "        term2 = (3 * one_minus_t * t**2)[:, None] * self.P2[None, :]\n",
    "        term3 = (t**3)[:, None] * self.P3[None, :]\n",
    "\n",
    "        return term0 + term1 + term2 + term3\n",
    "\n",
    "    def bezier_x(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Get x-coordinate of Bézier curve at parameter t\"\"\"\n",
    "        return self.bezier_point(t)[:, 0]  # Changed from [..., 0]\n",
    "\n",
    "    def bezier_y(self, t: Tensor) -> Tensor:\n",
    "        \"\"\"Get y-coordinate of Bézier curve at parameter t\"\"\"\n",
    "        return self.bezier_point(t)[:, 1]  # Changed from [..., 1]\n",
    "\n",
    "    def solve_for_t(self, x: Tensor, max_iters: int = 10) -> Tensor:\n",
    "        \"\"\"Solve for parameter t such that bezier_x(t) = x using Newton's method\"\"\"\n",
    "        # Initial guess: linear interpolation\n",
    "        t = (x - self.a) / (1 - self.a)\n",
    "        t = torch.clamp(t, 0.01, 0.99)  # Avoid endpoints\n",
    "\n",
    "        for _ in range(max_iters):\n",
    "            # Newton step: t_new = t - f(t)/f'(t)\n",
    "            # where f(t) = bezier_x(t) - target_x\n",
    "\n",
    "            # Enable gradients for automatic differentiation\n",
    "            t_var = t.clone().requires_grad_(True)\n",
    "            x_pred = self.bezier_x(t_var)\n",
    "            error = x_pred - x\n",
    "\n",
    "            # Compute derivative dx/dt\n",
    "            dx_dt = torch.autograd.grad(x_pred.sum(), t_var, create_graph=False)[0]\n",
    "\n",
    "            # Newton update (be careful with division by zero)\n",
    "            dt = error / (dx_dt + 1e-8)\n",
    "            t = t - dt\n",
    "            t = torch.clamp(t, 0.0, 1.0)\n",
    "\n",
    "            # Check convergence\n",
    "            if torch.max(torch.abs(error)) < 1e-6:\n",
    "                break\n",
    "\n",
    "        return t\n",
    "\n",
    "    @override\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        result = alignment.clone()\n",
    "\n",
    "        # Only apply Bézier mapping for alignment > a\n",
    "        mask = alignment > self.a\n",
    "        if mask.any():\n",
    "            x_vals = alignment[mask]\n",
    "\n",
    "            # Solve for t parameters\n",
    "            t_vals = self.solve_for_t(x_vals)\n",
    "\n",
    "            # Get corresponding y values\n",
    "            y_vals = self.bezier_y(t_vals)\n",
    "\n",
    "            result[mask] = y_vals\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'BezierMapper(a={self.a:.2g}, b={self.b:.2g})'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Bézier[{self.a:.2g}→{self.b:.2g}]'\n",
    "\n",
    "\n",
    "class FastBezierMapper(BezierMapper):\n",
    "    def __init__(self, *args, lookup_resolution: int = 1000, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Precompute lookup table\n",
    "        t_vals = torch.linspace(0, 1, lookup_resolution, dtype=torch.float32)\n",
    "        bezier_points = self.bezier_point(t_vals)\n",
    "\n",
    "        # Ensure contiguous storage to avoid searchsorted warning\n",
    "        self.x_lookup = bezier_points[:, 0].contiguous()  # x coordinates\n",
    "        self.y_lookup = bezier_points[:, 1].contiguous()  # y coordinates\n",
    "\n",
    "    def interpolate_1d(self, x_query: Tensor) -> Tensor:\n",
    "        \"\"\"1D linear interpolation using lookup table\"\"\"\n",
    "        # Find insertion points for x_query in x_lookup\n",
    "        indices = torch.searchsorted(self.x_lookup, x_query, right=False)\n",
    "\n",
    "        # Clamp indices to valid range\n",
    "        indices = torch.clamp(indices, 1, len(self.x_lookup) - 1)\n",
    "\n",
    "        # Get surrounding points\n",
    "        x0 = self.x_lookup[indices - 1]\n",
    "        x1 = self.x_lookup[indices]\n",
    "        y0 = self.y_lookup[indices - 1]\n",
    "        y1 = self.y_lookup[indices]\n",
    "\n",
    "        # Linear interpolation: y = y0 + (y1 - y0) * (x - x0) / (x1 - x0)\n",
    "        t = (x_query - x0) / (x1 - x0 + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "        y_interp = y0 + t * (y1 - y0)\n",
    "\n",
    "        return y_interp\n",
    "\n",
    "    @override\n",
    "    def __call__(self, alignment: Tensor) -> Tensor:\n",
    "        result = alignment.clone()\n",
    "        mask = alignment > self.a\n",
    "\n",
    "        if mask.any():\n",
    "            x_vals = alignment[mask]\n",
    "\n",
    "            # Use interpolation on lookup table instead of Newton's method\n",
    "            y_vals = self.interpolate_1d(x_vals)\n",
    "\n",
    "            result[mask] = y_vals\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def draw_bezier_handle(cp1: Tensor, cp2: Tensor, *, color: str, **kwargs):\n",
    "    cx, cy = zip(cp1, cp2, strict=True)\n",
    "    ax.plot(\n",
    "        cx,\n",
    "        cy,\n",
    "        color=color,\n",
    "        linewidth=1.5,\n",
    "        zorder=0,\n",
    "        **kwargs,\n",
    "    )\n",
    "    ax.plot(\n",
    "        cx,\n",
    "        cy,\n",
    "        color=color,\n",
    "        linestyle=' ',\n",
    "        marker='o',\n",
    "        markersize=4,\n",
    "        markerfacecolor='black',\n",
    "        markeredgewidth=1.2,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a smooth curve from a=0.5 to b=0.866 with slope=1 at start\n",
    "bezier_falloff = FastBezierMapper(\n",
    "    a=cos(pi / 3),\n",
    "    b=cos(pi / 6),\n",
    "    start_slope=1.0,  # Continue identity slope\n",
    "    end_slope=0.0,  # Gentle approach to endpoint\n",
    ")\n",
    "\n",
    "title = 'Mapping function (Bézier)'\n",
    "with displayer_img(\n",
    "    f'large-assets/ex-{nb_id}-bezier-mapping.png',\n",
    "    alt_text=f\"\"\"A graph titled '{title}' showing how input cosine similarity values are transformed by the intervention. The x-axis shows 'Cosine similarity (angle from subject)' ranging from 180° (opposing) on the left to 0° (aligned) on the right, passing through 90° (orthogonal) in the middle. The y-axis shows 'Output cosine similarity' with the same angular scale from 180° at bottom to 0° at top. A diagonal gray 'Identity' line runs from bottom-left to top-right, representing no transformation. Two dashed reference lines mark key parameters: a vertical magenta line 'a' at approximately 60° and an orange horizontal line 'b' at approximately 30°. The main white curve labeled 'activation alignment' follows the identity line until reaching the 'a' threshold, then smoothly curves to the right, demonstrating how the Bézier function maps highly aligned inputs (near 0°) to the target output value 'b' (30°). This illustrates the intervention's effect: activations below the 'a' threshold remain unchanged, while those above are smoothly redirected according to the Bézier curve.\"\"\",\n",
    ") as show:\n",
    "    fig = plt.figure(1, (6, 6))\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    # Use generic linear mapping drawer\n",
    "    draw_mapping_linear(ax, bezier_falloff, title=title)\n",
    "\n",
    "    # Control points overlay\n",
    "    draw_bezier_handle(bezier_falloff.P0, bezier_falloff.P1, color='hotpink')\n",
    "    draw_bezier_handle(bezier_falloff.P2, bezier_falloff.P3, color='orange')\n",
    "\n",
    "    ax.legend(frameon=False, fontsize='small')\n",
    "\n",
    "    show(fig)\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191d5190",
   "metadata": {},
   "source": [
    "# Experiment 2.2: Specific concept intervention\n",
    "\n",
    "In the [1.x series](../../README.md#m1-preliminary-experiments-with-color) of experiments (milestone 1), we validated our ideas for imposing structure on latent space. With only weak supervision, we guided a simple RGB autoencoder to use the color wheel for its latent representations. In this series, we'll try to inhibit and even delete certain concepts from the model.\n",
    "\n",
    "To start, let's take one of the earlier experiments and see what happens when we suppress activations that align with _red_.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "We've structured the latent space so red is located at $[1,0,0,0]$. If we suppress or redirect activations close to that vector, model performance on near-red colors should drop, while other colors remain mostly unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf0edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup: Logging, Experiment (Modal)\n",
    "from __future__ import annotations\n",
    "import logging\n",
    "\n",
    "import modal\n",
    "\n",
    "from infra.requirements import freeze, project_packages\n",
    "from mini.experiment import Experiment\n",
    "from utils.logging import SimpleLoggingConfig\n",
    "\n",
    "logging_config = (\n",
    "    SimpleLoggingConfig()\n",
    "    .info('notebook', 'utils', 'mini', 'ex_color')\n",
    "    .error('matplotlib.axes')  # Silence warnings about set_aspect\n",
    ")\n",
    "logging_config.apply()\n",
    "\n",
    "# ID for tagging assets\n",
    "nbid = '2.2'\n",
    "# This is the logger for this notebook\n",
    "log = logging.getLogger(f'notebook.{nbid}')\n",
    "experiment_name = f'ex-color-{nbid}'\n",
    "\n",
    "run = Experiment(experiment_name)\n",
    "run.image = modal.Image.debian_slim().pip_install(*freeze(all=True)).add_local_python_source(*project_packages())\n",
    "run.before_each(logging_config.apply)\n",
    "None  # prevent auto-display of this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2028d",
   "metadata": {},
   "source": [
    "## Regularizers\n",
    "\n",
    "Like Ex 1.7:\n",
    "\n",
    "- **Anchor:** pins `red` to $(1,0,0,0)$\n",
    "- **Separate:** angular repulsion to reduce global clumping (applied within each batch)\n",
    "- **Planarity:** pulls vibrant hues to the $[0, 1]$ plane\n",
    "- **Unitarity:** pulls all embeddings to the surface of the unit hypersphere, i.e. it makes the embedding vectors have unit length. There are two terms: one that affects all colors equally, and another that just operates on the vibrant colors (because they seemed to need a little more help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10c434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mini.temporal.dopesheet import Dopesheet\n",
    "from ex_color.loss import Anchor, Separate, Planarity, Unitarity, RegularizerConfig\n",
    "from ex_color.model import ColorMLP\n",
    "from ex_color.training import TrainingModule\n",
    "\n",
    "RED = (1, 0, 0, 0)\n",
    "\n",
    "ALL_REGULARIZERS = [\n",
    "    RegularizerConfig(\n",
    "        name='reg-anchor',\n",
    "        compute_loss_term=Anchor(torch.tensor(RED, dtype=torch.float32)),\n",
    "        label_affinities={'red': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-separate',\n",
    "        compute_loss_term=Separate(power=10.0, shift=False),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-planar',\n",
    "        compute_loss_term=Planarity(),\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-unit-v',\n",
    "        compute_loss_term=Unitarity(),\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-unit',\n",
    "        compute_loss_term=Unitarity(),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376072",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is the same as last time:\n",
    "- Train: an HSV cube (of RGB values)\n",
    "- Test: an RGB cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de07fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cube_sampler import vibrancy\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "from ex_color.labelling import collate_with_generated_labels\n",
    "\n",
    "\n",
    "def prep_data() -> tuple[DataLoader, Tensor]:\n",
    "    \"\"\"\n",
    "    Prepare data for training.\n",
    "\n",
    "    Returns: (train, val)\n",
    "    \"\"\"\n",
    "    hsv_cube = ColorCube.from_hsv(\n",
    "        h=arange_cyclic(step_size=10 / 360),\n",
    "        s=np.linspace(0, 1, 10),\n",
    "        v=np.linspace(0, 1, 10),\n",
    "    )\n",
    "    hsv_tensor = torch.tensor(hsv_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    vibrancy_tensor = torch.tensor(vibrancy(hsv_cube).flatten(), dtype=torch.float32)\n",
    "    hsv_dataset = TensorDataset(hsv_tensor, vibrancy_tensor)\n",
    "\n",
    "    labeller = partial(\n",
    "        collate_with_generated_labels,\n",
    "        soft=False,  # Use binary labels (stochastic) to simulate the labelling of internet text\n",
    "        red=0.5,\n",
    "        vibrant=0.5,\n",
    "    )\n",
    "    # Desaturated and dark colors are over-represented in the cube, so we use a weighted sampler to balance them out\n",
    "    hsv_loader = DataLoader(\n",
    "        hsv_dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=2,\n",
    "        sampler=WeightedRandomSampler(\n",
    "            weights=hsv_cube.bias.flatten().tolist(),\n",
    "            num_samples=len(hsv_dataset),\n",
    "            replacement=True,\n",
    "        ),\n",
    "        collate_fn=labeller,\n",
    "    )\n",
    "\n",
    "    rgb_cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 8),\n",
    "        g=np.linspace(0, 1, 8),\n",
    "        b=np.linspace(0, 1, 8),\n",
    "    )\n",
    "    rgb_tensor = torch.tensor(rgb_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    return hsv_loader, rgb_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb906",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "_Unlike_ earlier experiments, we've switched over to use PyTorch Lightning instead of our custom training loop. We also tried porting to Catalyst and Ignite, but we found that Lightning was the closest match to the shape that our training code had evolved into.\n",
    "\n",
    "Functionally, not much has changed at this point, but now we should be able to take advantage of things like [Lightning's distributed processing support](https://lightning.ai/docs/pytorch/stable/api_references.html#strategies).\n",
    "\n",
    "We have also switched to using Modal for remote compute, and Weights and Biases for experiment tracking. We also tried running our own Aim experiment tracker instance. It worked, but it was slow. We're not sure why; maybe we just hadn't configured the storage or networking properly. If you're curious, check out the [`aim` tag in the Git history](https://github.com/z0u/ex-color-transformer/tree/aim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c22398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4.8 no.2.2:  Training with: ['reg-anchor', 'reg-separate', 'reg-planar', 'reg-unit-v', 'reg-unit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4.8 li.fa.ut.se:Seed set to 0\n",
      "I 4.8 ex.se:   PyTorch set to deterministic mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4.8 li.py.ut.ra:GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4.8 li.py.ut.ra:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4.8 li.py.ut.ra:HPU available: False, using: 0 HPUs\n",
      "max_steps: 20001, hsv_loader length: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mz0r\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.6s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250905_065602-stbvl7i5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/z0r/ex-color-transformer/runs/stbvl7i5' target=\"_blank\">ex-color-2.2</a></strong> to <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/z0r/ex-color-transformer/runs/stbvl7i5' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/stbvl7i5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width: 100%; padding: 5px 0; font-family: monospace\">\n",
       "  <div style=\"position: relative; height: calc(1em * 5/3); width: 100%; margin-bottom: 2em\">\n",
       "    <div style=\"position: absolute; top: 100%; height: 3.5px; left: 0; width: 100%; background: linear-gradient(to right, var(--h1) 0.0%, var(--h0) 2.0%, var(--h0) 4.1%, var(--h0) 6.1%, var(--h0) 8.2%, var(--h0) 10.2%, var(--h0) 12.2%, var(--h0) 14.3%, var(--h0) 16.3%, var(--h0) 18.4%, var(--h0) 20.4%, var(--h0) 22.4%, var(--h0) 24.5%, var(--h0) 26.5%, var(--h0) 28.6%, var(--h0) 30.6%, var(--h0) 32.7%, var(--h0) 34.7%, var(--h0) 36.7%, var(--h0) 38.8%, var(--h0) 40.8%, var(--h0) 42.9%, var(--h0) 44.9%, var(--h0) 46.9%, var(--h0) 49.0%, var(--h0) 51.0%, var(--h0) 53.1%, var(--h0) 55.1%, var(--h0) 57.1%, var(--h0) 59.2%, var(--h0) 61.2%, var(--h0) 63.3%, var(--h0) 65.3%, var(--h0) 67.3%, var(--h0) 69.4%, var(--h0) 71.4%, var(--h0) 73.5%, var(--h0) 75.5%, var(--h0) 77.6%, var(--h0) 79.6%, var(--h0) 81.6%, var(--h0) 83.7%, var(--h0) 85.7%, var(--h0) 87.8%, var(--h0) 89.8%, var(--h0) 91.8%, var(--h0) 93.9%, var(--h0) 95.9%, var(--h0) 98.0%, var(--h1) 100.0%);--h0:color(from currentColor srgb r g b / 0.60);--h1:color(from currentColor srgb r g b / 0.79)\"></div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 0.3%; border-left: 0.5px solid currentColor\">0.0378</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 10.0%; border-left: 0.5px solid currentColor\">0.0197</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 19.7%; border-left: 0.5px solid currentColor\">0.0190</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 29.3%; border-left: 0.5px solid currentColor\">0.0141</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 39.0%; border-left: 0.5px solid currentColor\">0.0065</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 48.7%; border-left: 0.5px solid currentColor\">0.0062</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 58.4%; border-left: 0.5px solid currentColor\">0.0034</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 68.1%; border-left: 0.5px solid currentColor\">0.0032</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 77.8%; border-left: 0.5px solid currentColor\">0.0022</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 87.5%; border-left: 0.5px solid currentColor\">0.0019</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; right: 0.0%; border-right: 0.5px solid currentColor\">0.0041</div>\n",
       "    <div style=\"position: absolute; bottom: -4px; left: calc(100.0% - 4px)\">\n",
       "      <div style=\"border-left: 4px solid transparent; border-right: 4px solid transparent; border-bottom: 4px solid currentColor\"></div>\n",
       "    </div>\n",
       "    <div style=\"position: absolute; height: 100%; width: 100.0%; background-color: color(from currentColor srgb r g b / 0.1); border-bottom: 1px solid currentColor\"></div>\n",
       "    <div style=\"position: absolute; width: 100%; height: 100%; text-align: center; line-height: calc((1em * 5/3) / 0.9); font-size: 90%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; border-bottom: 1px dashed color(from currentColor srgb r g b / 0.5)\"><b>Training</b>: 100.0% [20001/20001] [<b>01:57</b>/<00:00, 170.10 it/s]</div>\n",
       "  </div>\n",
       "  <div style=\"display: grid; grid-template-columns: repeat(2, minmax(80px, 1fr)); gap: 5px 0px; width: 100%; margin: 1em 0; font-size: 0.85em\">\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">v_num</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">train_loss</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">l7i5</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">0.00412</div>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "Training: 100.0% [20001/20001]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phase: Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=20001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 124.6 li.py.ut.ra:`Trainer.fit` stopped: `max_steps=20001` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>▅▇█▇▆▇▇▇█▅▅▃▆▃▃▃▄▂▂▂▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_recon</td><td>▆▆█▅▅▄▅▂▂▃▂▂▂▃▄▃▂▂▂▂▃▃▂▃▂▁▂▁▁▂▂▁▄▂▁▁▁▂▁▁</td></tr><tr><td>train_reg-anchor</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_reg-planar</td><td>▄▂▄▂▄▃█▁█▁▂▁▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▂▁▁▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>train_reg-separate</td><td>▃▃▃▇▄▁▃▃▂▁▄▂▂▆▄▄▅▃▅▆▇▇▆▅█▆▆▇▇▆▅▇▄▄▄▄▇█▄▅</td></tr><tr><td>train_reg-unit</td><td>█▆▅▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-unit-v</td><td>█▅▂▂▁▁▂▁▂▁▁▂▁▃▂▁▂▂▂▂▁▁▁▁▁▁▂▁▁▂▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>350</td></tr><tr><td>train_loss</td><td>0.0043</td></tr><tr><td>train_recon</td><td>0.00064</td></tr><tr><td>train_reg-anchor</td><td>0</td></tr><tr><td>train_reg-planar</td><td>0</td></tr><tr><td>train_reg-separate</td><td>3.14612</td></tr><tr><td>train_reg-unit</td><td>0.00261</td></tr><tr><td>train_reg-unit-v</td><td>0</td></tr><tr><td>trainer/global_step</td><td>19999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ex-color-2.2</strong> at: <a href='https://wandb.ai/z0r/ex-color-transformer/runs/stbvl7i5' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer/runs/stbvl7i5</a><br> View project at: <a href='https://wandb.ai/z0r/ex-color-transformer' target=\"_blank\">https://wandb.ai/z0r/ex-color-transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250905_065602-stbvl7i5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from ex_color.inference import InferenceModule\n",
    "from ex_color.intervention.intervention import InterventionConfig\n",
    "\n",
    "\n",
    "# @run.thither(env={'WANDB_API_KEY': wandb.Api().api_key})\n",
    "async def train(\n",
    "    dopesheet: Dopesheet,\n",
    "    regularizers: list[RegularizerConfig],\n",
    ") -> ColorMLP:\n",
    "    \"\"\"Train the model with the given dopesheet and variant.\"\"\"\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    from ex_color.seed import set_deterministic_mode\n",
    "\n",
    "    from utils.progress.lightning import LightningProgress\n",
    "\n",
    "    log.info(f'Training with: {[r.name for r in regularizers]}')\n",
    "\n",
    "    seed = 0\n",
    "    set_deterministic_mode(seed)\n",
    "\n",
    "    hsv_loader, _ = prep_data()\n",
    "\n",
    "    model = ColorMLP(4)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log.debug(f'Model initialized with {total_params:,} trainable parameters.')\n",
    "\n",
    "    training_module = TrainingModule(model, dopesheet, torch.nn.MSELoss(), regularizers)\n",
    "\n",
    "    logger = WandbLogger(experiment_name, project='ex-preppy')\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_steps=len(dopesheet),\n",
    "        callbacks=[\n",
    "            LightningProgress(),\n",
    "        ],\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        # enable_progress_bar=True,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    print(f'max_steps: {len(dopesheet)}, hsv_loader length: {len(hsv_loader)}')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        trainer.fit(training_module, hsv_loader)\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "    # This is only a small model, so it's OK to return it rather than storing and loading a checkpoint remotely\n",
    "    return model\n",
    "\n",
    "\n",
    "async with run():\n",
    "    model = await train(Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv'), ALL_REGULARIZERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9688ac3",
   "metadata": {},
   "source": [
    "## Inference ('test-time')\n",
    "\n",
    "We wrap the model that we trained above in an `InferenceModule`, which knows how to apply our interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d2de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @run.thither\n",
    "async def infer(\n",
    "    model: ColorMLP,\n",
    "    interventions: list[InterventionConfig],\n",
    "    test_data: Tensor,\n",
    ") -> Tensor:\n",
    "    \"\"\"Run inference with the given model and interventions.\"\"\"\n",
    "    import lightning as L\n",
    "\n",
    "    inference_module = InferenceModule(model, interventions)\n",
    "    trainer = L.Trainer(\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    reconstructed_colors_batches = trainer.predict(\n",
    "        inference_module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert reconstructed_colors_batches is not None\n",
    "    # Flatten the list of batches to a single list of tensors\n",
    "    reconstructed_colors = [item for batch in reconstructed_colors_batches for item in batch]\n",
    "    # Reshape to match input\n",
    "    return torch.cat(reconstructed_colors).reshape(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6940577",
   "metadata": {},
   "source": [
    "Let's see how well the model reconstructs colors _without_ any interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4381b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-true-colors.dark.png?v=BV5nUvb8r8A8rSCU0DTLyj7wB6EAHHpX6W-Rap8tsKw\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-true-colors.png?v=BV5nUvb8r8A8rSCU0DTLyj7wB6EAHHpX6W-Rap8tsKw\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-true-colors.png?v=BV5nUvb8r8A8rSCU0DTLyj7wB6EAHHpX6W-Rap8tsKw\" alt=\"Plot showing four slices of the HSV cube, titled &quot;True colors - HSV as H,V per S&quot;. Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"True colors - HSV as H,V per S\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from utils.nb import displayer_mpl\n",
    "from ex_color.vis import plot_colors\n",
    "\n",
    "\n",
    "hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 24),\n",
    "    s=np.linspace(0, 1, 4),\n",
    "    v=np.linspace(0, 1, 8),\n",
    ").permute('svh')\n",
    "x_hsv = torch.tensor(hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "hd_hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 240),\n",
    "    s=np.linspace(0, 1, 48),\n",
    "    v=np.linspace(0, 1, 48),\n",
    ")\n",
    "hd_x_hsv = torch.tensor(hd_hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "rgb_cube = ColorCube.from_rgb(\n",
    "    r=np.linspace(0, 1, 20),\n",
    "    g=np.linspace(0, 1, 20),\n",
    "    b=np.linspace(0, 1, 20),\n",
    ")\n",
    "x_rgb = torch.tensor(rgb_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-true-colors.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"True colors - HSV as H,V per S\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\"\"\",\n",
    ") as show:\n",
    "    show(lambda: plot_colors(hsv_cube, title='True colors', colors=x_hsv.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14da6f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-no-intervention.dark.png?v=8fLGC1V1It5aToefzSPqfLw9Tr8hTBAlYhnaSjSoFxA\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-no-intervention.png?v=8fLGC1V1It5aToefzSPqfLw9Tr8hTBAlYhnaSjSoFxA\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-pred-colors-no-intervention.png?v=8fLGC1V1It5aToefzSPqfLw9Tr8hTBAlYhnaSjSoFxA\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors without intervention - HSV as H,V per S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but some slight differences are visible; for example, &quot;white&quot; is slightly gray, and many of the fully-saturated colors are less saturated than they should be.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors without intervention - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but some slight differences are visible; for example, \"white\" is slightly gray, and many of the fully-saturated colors are less saturated than they should be."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-no-intervention.dark.png?v=fG_Dy7fmiKv3P8Y_XkqvkaumZottMlCyYSpIF03PbW4\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-no-intervention.png?v=fG_Dy7fmiKv3P8Y_XkqvkaumZottMlCyYSpIF03PbW4\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-loss-colors-no-intervention.png?v=fG_Dy7fmiKv3P8Y_XkqvkaumZottMlCyYSpIF03PbW4\" alt=\"Line chart showing loss per color, for colors reconstructed by the model without any intervention. Y-axis: mean square error, ranging from zero to 0.014. X-axis: hue. The range of loss values is small, but there are notable peaks at blue and red. The loss for other colors is low, but varies in a wavy pattern.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, for colors reconstructed by the model without any intervention. Y-axis: mean square error, ranging from zero to 0.014. X-axis: hue. The range of loss values is small, but there are notable peaks at blue and red. The loss for other colors is low, but varies in a wavy pattern."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.014\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "interventions = []\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-no-intervention.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"Predicted colors without intervention - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but some slight differences are visible; for example, \"white\" is slightly gray, and many of the fully-saturated colors are less saturated than they should be.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors without intervention',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-no-intervention.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, for colors reconstructed by the model without any intervention. Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. The range of loss values is small, but there are notable peaks at blue and red. The loss for other colors is low, but varies in a wavy pattern.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            title='Reconstruction error · no intervention',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c6e78",
   "metadata": {},
   "source": [
    "That's pretty good: as expected, the reconstructed colors (predictions) _look_ almost the same as the true colors. Visually, the main differences I can see are:\n",
    "\n",
    "- Fully saturated colors ($s=1$) show some bleeding of green, red, and hot pink into neighboring hues\n",
    "- Fully desaturated colors ($s=0$) show some hint of being slightly off-gray, i.e. some saturation has crept in.\n",
    "\n",
    "Sense-check: let's look at the latent space too. We'll use an RGB cube as input for this instead of the HSV cube used above, because it gives a more regular distribution of points — which will be useful to see whether the intervention changes the point density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ec7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ex_color.inference import InferenceModule\n",
    "\n",
    "\n",
    "# Build a tiny helper that runs predict while capturing latents from 'encoder'\n",
    "async def infer_with_latent_capture(\n",
    "    model: ColorMLP, interventions: list[InterventionConfig], test_data: Tensor, layer_name: str = 'encoder'\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    module = InferenceModule(model, interventions, capture_layers=[layer_name])\n",
    "    import lightning as L\n",
    "\n",
    "    trainer = L.Trainer(enable_checkpointing=False, enable_model_summary=False, enable_progress_bar=False)\n",
    "    batches = trainer.predict(\n",
    "        module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert batches is not None\n",
    "    preds = [item for batch in batches for item in batch]\n",
    "    y = torch.cat(preds).reshape(test_data.shape)\n",
    "    # Read captured activations as a flat [N, D] tensor\n",
    "    latents = module.read_captured(layer_name)\n",
    "    return y, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4aa8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-no-intervention.dark.png?v=ltg3D6A5UC8MJockMNStv8gcD1Q_LXZNNzTF2bixj8A\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-no-intervention.png?v=ltg3D6A5UC8MJockMNStv8gcD1Q_LXZNNzTF2bixj8A\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-latents-no-intervention.png?v=ltg3D6A5UC8MJockMNStv8gcD1Q_LXZNNzTF2bixj8A\" alt=\"Three spherical plots, titled &quot;Latents - no intervention&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree fairly well, but slight differences can be seen if you look closely.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents - no intervention\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree fairly well, but slight differences can be seen if you look closely."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, [], x_rgb, 'encoder')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-no-intervention.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"Latents - no intervention\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a color wheel, with the full set of vibrant colors around the rim (like a rainbow), varying to black in the center. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and red in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. In this plot the true and reconstructor colors agree fairly well, but slight differences can be seen if you look closely.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · no intervention',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68adcf20",
   "metadata": {},
   "source": [
    "The looks reasonable: similar to Ex 1.7, the latent space shows a color wheel in the first two axes with red near the top. It looks lumpier than I expected, which may mess with the interventions, since they expect unit norm embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4f1dc",
   "metadata": {},
   "source": [
    "## Suppression\n",
    "\n",
    "Now that we have our model, let's try suppressing _red_. We'll use the `Suppression` function developed in [Ex 2.1](./ex-2.1-intervention-lobe.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8cecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-suppression.dark.png?v=4Yr7mXkh0XrS57MliMFFfWR2-qKvf-_ZnSsXbofQYz0\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-suppression.png?v=4Yr7mXkh0XrS57MliMFFfWR2-qKvf-_ZnSsXbofQYz0\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-pred-colors-suppression.png?v=4Yr7mXkh0XrS57MliMFFfWR2-qKvf-_ZnSsXbofQYz0\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors with suppression - HSV as H,V per S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but &quot;red&quot; and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. &quot;Red-orange&quot; actually appears to be green, moreso even than yellow (which is geometrically closer to green).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors with suppression - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. \"Red-orange\" actually appears to be green, moreso even than yellow (which is geometrically closer to green)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-suppression.dark.png?v=PznPfyboI3jp7lopQpx1IkeMZz39R5YoQ22p5-Iquw0\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-suppression.png?v=PznPfyboI3jp7lopQpx1IkeMZz39R5YoQ22p5-Iquw0\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-loss-colors-suppression.png?v=PznPfyboI3jp7lopQpx1IkeMZz39R5YoQ22p5-Iquw0\" alt=\"Line chart showing loss per color, for colors reconstructed by the model with suppression of red. Y-axis: mean square error, ranging from zero to 0.28. X-axis: hue. There is a significant peak at red at either end of the X-axis, sloping down like a bell curve to low values near yellow and blue. Two small peaks are at blue and pink, with the one at pink around one third the height of the peaks at red.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, for colors reconstructed by the model with suppression of red. Y-axis: mean square error, ranging from zero to 0.28. X-axis: hue. There is a significant peak at red at either end of the X-axis, sloping down like a bell curve to low values near yellow and blue. Two small peaks are at blue and pink, with the one at pink around one third the height of the peaks at red."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.28\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "\n",
    "import torch\n",
    "\n",
    "from ex_color.intervention import BoundedFalloff, InterventionConfig, Suppression\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "suppression = Suppression(\n",
    "    torch.tensor(RED, dtype=torch.float32),  # Constant!\n",
    "    BoundedFalloff(\n",
    "        0,  # within 60°\n",
    "        1,  # completely squash fully-aligned vectors\n",
    "        2,  # soft rim, sharp hub\n",
    "    ),\n",
    ")\n",
    "\n",
    "interventions = [InterventionConfig(suppression, ['encoder'])]\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-suppression.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"Predicted colors with suppression - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different: red itself appears as middle-gray, and the surrounding colors up to orange and pink look washed out. \"Red-orange\" actually appears to be green, moreso even than yellow (which is geometrically closer to green).\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors with suppression',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-suppression.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, for colors reconstructed by the model with suppression of red. Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. There is a significant peak at red at either end of the X-axis, sloping down like a bell curve to low values near yellow and blue. Two small peaks are at blue and pink, with the one at pink around one third the height of the peaks at red.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            title='Reconstruction error · suppression',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d35e4b3",
   "metadata": {},
   "source": [
    "Good! The colors near red have been perturbed, with the effect diminishing on approach to black, yellow, and hot pink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec409f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-suppression.dark.png?v=4u4Wwtyl3x-8TUhU8wmVrUvn4ZFvnVyL4Tn0weZbVSc\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-suppression.png?v=4u4Wwtyl3x-8TUhU8wmVrUvn4ZFvnVyL4Tn0weZbVSc\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-latents-suppression.png?v=4u4Wwtyl3x-8TUhU8wmVrUvn4ZFvnVyL4Tn0weZbVSc\" alt=\"Three spherical plots, titled &quot;Latents - suppression&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where &quot;red&quot; should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm-but-not-red colors in the center (where &quot;red&quot; should be). Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. &quot;Red&quot; and nearby colors are in fact not visible, being buried somewhere inside the sphere.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents - suppression\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm-but-not-red colors in the center (where \"red\" should be). Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. \"Red\" and nearby colors are in fact not visible, being buried somewhere inside the sphere."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d, ConicalAnnotation\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, interventions, x_rgb, 'encoder')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-suppression.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"Latents - suppression\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom, and warm-but-not-red colors in the center (where \"red\" should be). Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, even for the warmer colors. \"Red\" and nearby colors are in fact not visible, being buried somewhere inside the sphere.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · suppression',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "            annotations=[\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - suppression.falloff.a),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                    dashes=theme.val((8, 8), dark=(4, 4)),\n",
    "                    gapcolor=theme.val('#fff4', dark='#0004'),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4215",
   "metadata": {},
   "source": [
    "Wow! The way the top of the first plot has been squashed in looks just like the lobe plots from Ex 2.1.\n",
    "\n",
    "The plots on the right show the same data but looking head-on into the concept vector for _red_. In the original plots, the centres of these were red. It seems that red has been pushed inside the sphere and is being obscured by other points, so it's a little hard to see what's going on. But we can see from the cube slices above that the model has indeed had its capability to express _red_ interfered with.\n",
    "\n",
    "It's worth noting that the interior of the sphere is out of distribution from the perspective of the decoder (i.e. downstream from these latents). That's not great, because it should mean the behavior resulting from this intervention is poorly defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8eb019",
   "metadata": {},
   "source": [
    "## Repulsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-repulsion.dark.png?v=r-3_TW9U5wvDix9v0MmAs3DwOY0zS_jycNngTKIJxeI\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-pred-colors-repulsion.png?v=r-3_TW9U5wvDix9v0MmAs3DwOY0zS_jycNngTKIJxeI\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-pred-colors-repulsion.png?v=r-3_TW9U5wvDix9v0MmAs3DwOY0zS_jycNngTKIJxeI\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors with repulsion - HSV as H,V per S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but &quot;red&quot; and nearby colors are clearly different, and different again from how the suppression intervention looked: &quot;red&quot; itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. &quot;Red-orange&quot; actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors with repulsion - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different, and different again from how the suppression intervention looked: \"red\" itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. \"Red-orange\" actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-repulsion.dark.png?v=CJrC_n_trCpJrcu0dPzlP1Tmg575ycvwYKiQRnz1J9w\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-loss-colors-repulsion.png?v=CJrC_n_trCpJrcu0dPzlP1Tmg575ycvwYKiQRnz1J9w\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-loss-colors-repulsion.png?v=CJrC_n_trCpJrcu0dPzlP1Tmg575ycvwYKiQRnz1J9w\" alt=\"Line chart showing loss per color, for colors reconstructed by the model with repulsion from red. Y-axis: mean square error, ranging from zero to 0.29. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, for colors reconstructed by the model with repulsion from red. Y-axis: mean square error, ranging from zero to 0.29. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max MSE: 0.29\n"
     ]
    }
   ],
   "source": [
    "from math import cos, pi\n",
    "\n",
    "import torch\n",
    "\n",
    "from ex_color.intervention import FastBezierMapper, InterventionConfig, Repulsion\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "repulsion = Repulsion(\n",
    "    torch.tensor([1, 0, 0, 0], dtype=torch.float32),  # Constant!\n",
    "    FastBezierMapper(\n",
    "        0,  # Constrain effect to within 60° cone\n",
    "        cos(pi / 3),  # Create 30° hole (negative cone) around concept vector\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "interventions = [InterventionConfig(repulsion, ['encoder'])]\n",
    "y_hsv = await infer(model, interventions, x_hsv)\n",
    "hd_y_hsv = await infer(model, interventions, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-repulsion.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"Predicted colors with repulsion - HSV as H,V per S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color. The reconstructed and true colors agree fairly well, but \"red\" and nearby colors are clearly different, and different again from how the suppression intervention looked: \"red\" itself appears as pink or hot pink, and the surrounding colors up to orange and pink look shifted. \"Red-orange\" actually appears to be fully-saturated yellow. Overall the effect is as though the nearby colors have bled into the neighborhood of red.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors with repulsion',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-repulsion.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, for colors reconstructed by the model with repulsion from red. Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue. There is a significant peak at red at either end of the X-axis, gradually sloping down to lower loss values near yellow and pink. Two very small peaks are at green and blue (apparently around 1% of the height of the peaks at red).\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -6)],\n",
    "            title='Reconstruction error · repulsion',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max MSE: {max_loss:.2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d947b",
   "metadata": {},
   "source": [
    "I think this looks quite a lot better than the suppression result: red has been perturbed again, but this time it seems to have been pushed to nearby colors rather than the murky grays we saw previously — so this method seems to preserve more model behavior that we _didn't_ intend to intervene on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "083b6bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-repulsion.dark.png?v=zXnWtf6MdvprR_fFddvmu304IIWfyysGFmN1-HGYQQw\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.2-latents-repulsion.png?v=zXnWtf6MdvprR_fFddvmu304IIWfyysGFmN1-HGYQQw\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.2-latents-repulsion.png?v=zXnWtf6MdvprR_fFddvmu304IIWfyysGFmN1-HGYQQw\" alt=\"Three spherical plots, titled &quot;Latents - repulsion&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where &quot;red&quot; should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: &quot;Red&quot; and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to &quot;red&quot;, which roughly agree in saturation but differ significantly in tone and hue.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents - repulsion\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: \"Red\" and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to \"red\", which roughly agree in saturation but differ significantly in tone and hue."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d, ConicalAnnotation\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model, interventions, x_rgb, 'encoder')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-repulsion.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"Latents - repulsion\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a black sphere. The first plot has the appearance of a partial color wheel, with  vibrant colors around the rim (like a rainbow), with with a conspicuously absent space at the top where \"red\" should be. The other plots show different views of the same sphere, with hue varying across the equator and tone varying from top to bottom. The central region of the second and third plots show something interesting: \"Red\" and nearby colors have been arranged into a wide ring or disc, rather than being clustered in the center. Each ball shows the reconstructed color, with a dot in the center showing the true (input) color. The true and reconstructor colors agree fairly well, except for colors close to \"red\", which roughly agree in saturation but differ significantly in tone and hue.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · repulsion',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (1, 3, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "            annotations=[\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - repulsion.mapper.a),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                    dashes=theme.val((8, 8), dark=(4, 4)),\n",
    "                    gapcolor=theme.val('#fff4', dark='#0004'),\n",
    "                ),\n",
    "                ConicalAnnotation(\n",
    "                    RED,\n",
    "                    2 * (np.pi / 2 - repulsion.mapper.b),  # type: ignore\n",
    "                    color=theme.val('black', dark='#fffa'),\n",
    "                    linewidth=theme.val(0.5, dark=1),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b5643",
   "metadata": {},
   "source": [
    "Here we see that the reds have all been pushed away from the intervened-on concept vector, and have formed a ring around it. The two plots on the right show that the points have not been pushed into the sphere interior, which means they're more likely to still be in-distrubtion from the point of view of the decoder. However, the pre-intervention hypersphere isn't covered with points — if our intervention has pushed points into a previously empty region, that would still count as being out of distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17177769",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our hypothesis was largely confirmed: the interventions were able to increase the reconstruction loss for colors near _red_ without affecting untargeted colors.\n",
    "\n",
    "# Next steps\n",
    "\n",
    "Next I'd like to see if the results can be improved by including an explicit normalization step in the forward pass, so that we're not entirely relying on the regularization to shape the embeddings. I expect that will improve both color reconstruction and intervention effectiveness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

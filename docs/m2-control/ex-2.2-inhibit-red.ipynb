{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191d5190",
   "metadata": {},
   "source": [
    "# Experiment 2.2: Specific concept intervention\n",
    "\n",
    "In the [1.x series](/README.md#m1-preliminary-experiments-with-color) of experiments (milestone 1), we validated our ideas for imposing structure on latent space. With only weak supervision, we guided a simple RGB autoencoder to use the color wheel for its latent representations. In this series, we'll try to inhibit and even delete certain concepts from the model.\n",
    "\n",
    "To start, let's take one of the earlier experiments and see what happens when we suppress activations that align with _red_.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "We've structured the latent space so red is located at $[1,0,0,0]$. If we suppress or redirect activations close to that vector, model performance on near-red colors should drop, while other colors remain mostly unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf0edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup: Logging, Experiment (Modal)\n",
    "from __future__ import annotations\n",
    "import logging\n",
    "\n",
    "import modal\n",
    "\n",
    "from infra.requirements import freeze, project_packages\n",
    "from mini.experiment import Experiment\n",
    "from utils.logging import SimpleLoggingConfig\n",
    "\n",
    "logging_config = (\n",
    "    SimpleLoggingConfig()\n",
    "    .info('notebook', 'utils', 'mini', 'ex_color')\n",
    "    .error('matplotlib.axes')  # Silence warnings about set_aspect\n",
    ")\n",
    "logging_config.apply()\n",
    "\n",
    "# ID for tagging assets\n",
    "nbid = '2.2'\n",
    "# This is the logger for this notebook\n",
    "log = logging.getLogger(f'notebook.{nbid}')\n",
    "experiment_name = f'ex-color-{nbid}'\n",
    "\n",
    "run = Experiment(experiment_name)\n",
    "run.image = modal.Image.debian_slim().pip_install(*freeze(all=True)).add_local_python_source(*project_packages())\n",
    "run.before_each(logging_config.apply)\n",
    "None  # prevent auto-display of this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2028d",
   "metadata": {},
   "source": [
    "## Regularizers\n",
    "\n",
    "Like Ex 1.7:\n",
    "\n",
    "- **Anchor:** pins `red` to $(1,0,0,0)$\n",
    "- **Separate:** angular repulsion to reduce global clumping (applied within each batch)\n",
    "- **Planarity:** pulls vibrant hues to the $[0, 1]$ plane\n",
    "- **Unitarity:** pulls all embeddings to the surface of the unit hypersphere, i.e. it makes the embedding vectors have unit length. There are two terms: one that affects all colors equally, and another that just operates on the vibrant colors (because they seemed to need a little more help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mini.temporal.dopesheet import Dopesheet\n",
    "from ex_color.loss import Anchor, Separate, planarity, unitarity, RegularizerConfig\n",
    "from ex_color.model import ColorMLP\n",
    "from ex_color.training import TrainingModule\n",
    "\n",
    "RED = (1, 0, 0, 0)\n",
    "\n",
    "ALL_REGULARIZERS = [\n",
    "    RegularizerConfig(\n",
    "        name='reg-anchor',\n",
    "        compute_loss_term=Anchor(torch.tensor(RED, dtype=torch.float32)),\n",
    "        label_affinities={'red': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-separate',\n",
    "        compute_loss_term=Separate(power=10.0, shift=False),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-planar',\n",
    "        compute_loss_term=planarity,\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-unit-v',\n",
    "        compute_loss_term=unitarity,\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-unit',\n",
    "        compute_loss_term=unitarity,\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['encoder'],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7494f",
   "metadata": {},
   "source": [
    "## Interventions\n",
    "\n",
    "Now, we'll define an intervention to suppress the concept of 'red'. This will use the `steer_away` function, which projects the activations onto the subspace orthogonal to the 'red' vector we used in the `Anchor` regularizer. This should effectively remove the 'redness' from the model's representations at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57035cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ex_color.intervention.intervention import InterventionConfig\n",
    "\n",
    "RED_VECTOR = torch.tensor([1, 0, 0, 0], dtype=torch.float32)\n",
    "\n",
    "ALL_INTERVENTIONS = [\n",
    "    # InterventionConfig(...),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376072",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is the same as last time:\n",
    "- Train: an HSV cube (of RGB values)\n",
    "- Test: an RGB cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de07fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cube_sampler import vibrancy\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "from ex_color.labelling import collate_with_generated_labels\n",
    "\n",
    "\n",
    "def prep_data() -> tuple[DataLoader, Tensor]:\n",
    "    \"\"\"\n",
    "    Prepare data for training.\n",
    "\n",
    "    Returns: (train, val)\n",
    "    \"\"\"\n",
    "    hsv_cube = ColorCube.from_hsv(\n",
    "        h=arange_cyclic(step_size=10 / 360),\n",
    "        s=np.linspace(0, 1, 10),\n",
    "        v=np.linspace(0, 1, 10),\n",
    "    )\n",
    "    hsv_tensor = torch.tensor(hsv_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    vibrancy_tensor = torch.tensor(vibrancy(hsv_cube).flatten(), dtype=torch.float32)\n",
    "    hsv_dataset = TensorDataset(hsv_tensor, vibrancy_tensor)\n",
    "\n",
    "    labeller = partial(\n",
    "        collate_with_generated_labels,\n",
    "        soft=False,  # Use binary labels (stochastic) to simulate the labelling of internet text\n",
    "        scale={'red': 0.5, 'vibrant': 0.5},\n",
    "    )\n",
    "    # Desaturated and dark colors are over-represented in the cube, so we use a weighted sampler to balance them out\n",
    "    hsv_loader = DataLoader(\n",
    "        hsv_dataset,\n",
    "        batch_size=64,\n",
    "        sampler=WeightedRandomSampler(\n",
    "            weights=hsv_cube.bias.flatten().tolist(),\n",
    "            num_samples=len(hsv_dataset),\n",
    "            replacement=True,\n",
    "        ),\n",
    "        collate_fn=labeller,\n",
    "    )\n",
    "\n",
    "    rgb_cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 8),\n",
    "        g=np.linspace(0, 1, 8),\n",
    "        b=np.linspace(0, 1, 8),\n",
    "    )\n",
    "    rgb_tensor = torch.tensor(rgb_cube.rgb_grid.reshape(-1, 3), dtype=torch.float32)\n",
    "    return hsv_loader, rgb_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb906",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "_Unlike_ earlier experiments, we've switched over to use PyTorch Lightning instead of our custom training loop. We also tried porting to Catalyst and Ignite, but we found that Lightning was the closest match to the shape that our training code had evolved into.\n",
    "\n",
    "Functionally, not much has changed at this point, but now we should be able to take advantage of things like [Lightning's distributed processing support](https://lightning.ai/docs/pytorch/stable/api_references.html#strategies).\n",
    "\n",
    "We have also switched to using Modal for remote compute, and Weights and Biases for experiment tracking. We also tried running our own Aim experiment tracker instance. It worked, but it was slow. We're not sure why; maybe we just hadn't configured the storage or networking properly. If you're curious, check out the [`aim` tag in the Git history](https://github.com/z0u/ex-color-transformer/tree/aim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c22398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "I 0.3 no.2.1:  Training with: ['reg-anchor', 'reg-separate', 'reg-planar', 'reg-unit-v', 'reg-unit']\n",
      "I 0.3 ex.se:   PyTorch set to deterministic mode\n",
      "wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "wandb: Currently logged in as: z0r to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "max_steps: 2001, hsv_loader length: 57\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in ./wandb/run-20250807_084721-b25i121x\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run ex-color-2.1\n",
      "wandb: ⭐️ View project at https://wandb.ai/z0r/ex-color-transformer\n",
      "wandb: 🚀 View run at https://wandb.ai/z0r/ex-color-transformer/runs/b25i121x\n",
      "/usr/local/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=16` in the `DataLoader` to improve performance.\n",
      "\u001b[KStarting phase: Train1]\n",
      "\u001b[KTraining: 100.0% [2001/2001]\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from ex_color.inference import InferenceModule\n",
    "from ex_color.intervention.intervention import InterventionConfig\n",
    "\n",
    "wandb_api_key = wandb.Api().api_key\n",
    "\n",
    "\n",
    "@run.thither\n",
    "async def train(\n",
    "    dopesheet: Dopesheet,\n",
    "    regularizers: list[RegularizerConfig],\n",
    ") -> ColorMLP:\n",
    "    \"\"\"Train the model with the given dopesheet and variant.\"\"\"\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    from ex_color.seed import set_deterministic_mode\n",
    "\n",
    "    from utils.progress.lightning import LightningProgress\n",
    "\n",
    "    log.info(f'Training with: {[r.name for r in regularizers]}')\n",
    "\n",
    "    seed = 0\n",
    "    set_deterministic_mode(seed)\n",
    "\n",
    "    hsv_loader, rgb_tensor = prep_data()\n",
    "\n",
    "    model = ColorMLP(4)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log.debug(f'Model initialized with {total_params:,} trainable parameters.')\n",
    "\n",
    "    training_module = TrainingModule(model, dopesheet, torch.nn.MSELoss(), regularizers)\n",
    "\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    logger = WandbLogger(experiment_name, project='ex-color-transformer')\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_steps=len(dopesheet),\n",
    "        callbacks=[\n",
    "            LightningProgress(),\n",
    "        ],\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        # enable_progress_bar=True,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    print(f'max_steps: {len(dopesheet)}, hsv_loader length: {len(hsv_loader)}')\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(training_module, hsv_loader)\n",
    "    # This is only a small model, so it's OK to return it rather than storing and loading a checkpoint remotely\n",
    "    return model\n",
    "\n",
    "\n",
    "@run.thither\n",
    "async def infer(\n",
    "    model: ColorMLP,\n",
    "    interventions: list[InterventionConfig],\n",
    ") -> Tensor:\n",
    "    \"\"\"Run inference with the given model and interventions.\"\"\"\n",
    "    import lightning as L\n",
    "\n",
    "    _, rgb_tensor = prep_data()\n",
    "    inference_module = InferenceModule(model, interventions)\n",
    "    trainer = L.Trainer(\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    reconstructed_colors_batches = trainer.predict(\n",
    "        inference_module, DataLoader(TensorDataset(rgb_tensor), batch_size=64)\n",
    "    )\n",
    "    assert reconstructed_colors_batches is not None\n",
    "    # Flatten the list of batches to a single list of tensors\n",
    "    reconstructed_colors = [item for batch in reconstructed_colors_batches for item in batch]\n",
    "    return torch.cat(reconstructed_colors)\n",
    "\n",
    "\n",
    "async with run():\n",
    "    model = await train(Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv'), ALL_REGULARIZERS)\n",
    "\n",
    "    reconstructed_colors = await infer(model, ALL_INTERVENTIONS)\n",
    "    log.info(f'Reconstructed {reconstructed_colors.shape[0]} colors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4f1dc",
   "metadata": {},
   "source": [
    "## Suppression\n",
    "\n",
    "Now that we have our model, let's try suppressing _red_. We'll use the `Suppression` function developed in [Ex 2.1](./ex-2.1-intervention-lobe.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, pi\n",
    "import torch\n",
    "\n",
    "from ex_color.intervention.bounded_falloff import BoundedFalloff\n",
    "from ex_color.intervention.suppression import Suppression\n",
    "\n",
    "\n",
    "intervention = Suppression(\n",
    "    torch.tensor(RED, dtype=torch.float32),\n",
    "    BoundedFalloff(cos(pi / 3), 1.0, 2),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
